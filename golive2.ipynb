{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# golive2\n",
    "\n",
    "A continuation of the **golive** Jupyter notebook (keeping it stable).\n",
    "\n",
    "\n",
    "The pre-masked speed 'vv_masked' is the observation of interest: How does it vary over\n",
    "the course of several years? I can think of a couple 'color vis' approaches without much thought:\n",
    "\n",
    "\n",
    "1. Empirical: For each location and across annual time bins (say 1/10th of a year) accumulate \n",
    "mean speed and std dev with the idea of 're-coloring' everything by std dev / mean or for a given \n",
    "time using speed / mean speed. (Is this 'frequentist'?)\n",
    "\n",
    "\n",
    "2. Treat each location + time series as a vector and apply a clustering algorithm like k-means.\n",
    "(Is this 'bayesian'?)\n",
    "\n",
    "\n",
    "Accumulating these data is most easily done using the xarray \n",
    "\n",
    "\n",
    ": Do we generate a 2D array of lists\n",
    "that accumulate from each dataset? Or do we go with time built-in as a third dimension?  Each \n",
    "addition is from a pixel from the 819 (easting) x 828 (northing) grid; and at a certain mean-day; \n",
    "and with a particular L8 time interval (16, 32, 48, 64, 80). \n",
    "\n",
    "\n",
    "accumulator(x, y) += (t, dt, vx, vy, vv, corr, del_corr) \n",
    "\n",
    "\n",
    "Some screening on ingest: using lgo_mask and an ad hoc thresold on maximum speed.\n",
    "\n",
    "\n",
    "Post-hoc screening: vx, vy consistent with other observations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Python utility code\n",
    "from pathlib import Path\n",
    "home_d = str(Path.home()) + '/'\n",
    "data_d = home_d + 'data/'             # A non-repository location for datasets of interest\n",
    "\n",
    "def dirobj(obj): return [x for x in dir(obj) if not x.startswith('_')]\n",
    "\n",
    "def lsal(path=''):\n",
    "    import os\n",
    "    return os.popen('ls -al ' + path).readlines()\n",
    "\n",
    "def ShowGitHubImage(username, repo, folder, source, localpath, localname, width, height):\n",
    "    global home_d\n",
    "    import requests, shutil\n",
    "    from PIL import Image\n",
    "    outf = localpath + '/' + localname\n",
    "    f = 'https://raw.githubusercontent.com/' + username + '/' + repo + '/master/' + folder + '/' + source\n",
    "    a = requests.get(f, stream = True)\n",
    "    if a.status_code == 200:\n",
    "        with open(outf, 'wb') as f:\n",
    "            a.raw.decode_content = True\n",
    "            shutil.copyfileobj(a.raw, f)\n",
    "    return Image.open(outf).resize((width,height),Image.ANTIALIAS)\n",
    "\n",
    "def ShowLocalImage(path, filename, width, height):\n",
    "    from PIL import Image\n",
    "    f = path + '/' + filename \n",
    "    return Image.open(f).resize((width,height),Image.ANTIALIAS)\n",
    "\n",
    "# Test either of the 'Show Image' functions\n",
    "# ShowGitHubImage('robfatland', 'othermathclub', 'images/cellular', 'conus_textile_shell_2.png', home_d, 'ctextile.jpg', 450, 250)\n",
    "# ShowLocalImage(home_d, 'ctextile.jpg', 450, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utm\n",
      "Installing collected packages: utm\n",
      "Successfully installed utm-0.4.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# what we need to get stuff done\n",
    "!pip install utm\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from xarray import Dataset\n",
    "import numpy as np\n",
    "from ftplib import FTP\n",
    "import utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# file grabbing code... this takes a few minutes \n",
    "golive2_d = data_d + 'golive2/'\n",
    "\n",
    "if False:\n",
    "    ftp = FTP('dtn.rc.colorado.edu')\n",
    "    ftp.login()\n",
    "    ftp.cwd('work/nsidc0710/nsidc0710_landsat8_golive_ice_velocity_v1.1/p063_r018')\n",
    "    a=[]\n",
    "    ftp.dir(a.append)    # This is a rather tricky line of Python as it passes an append method as an argument\n",
    "    d = [b.split()[8] for b in a if len(b.split()) == 9 and b.split()[8][-3:]=='.nc']\n",
    "    for i in range(len(d)):\n",
    "        ftp.retrbinary('RETR ' + d[i], open(golive2_d + d[i], 'wb').write)  \n",
    "        print('obtained file', i)\n",
    "    ftp.quit()\n",
    "    print(len(d))\n",
    "    # for c in d: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "2013-05-31T00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                                         (chars: 4280, time: 1, x: 803, y: 786)\n",
       "Coordinates:\n",
       "  * x                                               (x) float64 3.373e+05 ...\n",
       "  * y                                               (y) float64 6.779e+06 ...\n",
       "  * chars                                           (chars) int32 0 1 2 3 4 ...\n",
       "  * time                                            (time) datetime64[ns] 2013-05-31 ...\n",
       "Data variables:\n",
       "    image_pair_times                                |S1 ...\n",
       "    input_image_details                             |S1 ...\n",
       "    transverse_mercator                             |S1 ...\n",
       "    offset_correction                               |S1 ...\n",
       "    applied_bilinear_x_offset_correction_in_pixels  (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    applied_bilinear_y_offset_correction_in_pixels  (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    vx                                              (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    vy                                              (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    vv                                              (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    vx_masked                                       (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    vy_masked                                       (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    vv_masked                                       (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    corr                                            (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    del_corr                                        (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    lgo_mask                                        (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    d2idx2                                          (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    d2jdx2                                          (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    del_i                                           (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    del_j                                           (y, x) float32 dask.array<shape=(786, 803), chunksize=(786, 803)>\n",
       "    processing_log                                  (chars) |S1 dask.array<shape=(4280,), chunksize=(4280,)>\n",
       "Attributes:\n",
       "    GDAL_AREA_OR_POINT:  Area\n",
       "    Conventions:         CF-1.6\n",
       "    history:             2016-11-30T21:02:35.316800 : /projects/makl5454/bin/...\n",
       "    GDAL:                GDAL 2.0.2, released 2016/01/26"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = xr.open_mfdataset(golive2_d + 'L8_063_018_016_2013_143_2013_159_v1.1.nc')\n",
    "# ds1['image_pair_times']\n",
    "# ds1['time'] = xr.Variable('time', ds1['image_pair_times'].attrs['mid_date'])\n",
    "# ds1\n",
    "print(type(ds['image_pair_times'].attrs['mid_date']))\n",
    "print(ds['image_pair_times'].attrs['mid_date'])\n",
    "s = ds['image_pair_times'].attrs['mid_date']\n",
    "ts = pd.Timestamp(s)\n",
    "ds['time'] = xr.Variable('time', [ts])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds1\n",
    "#ds1.squeeze('chars', drop=True)\n",
    "#ds1['vv_masked'].sel(x=':', )\n",
    "#del ds1['chars']\n",
    "#ds1 = ds1.sel(x=slice(-1), y=slice(-1))\n",
    "#ds1\n",
    "# def pp(ds1):\n",
    "#     del ds1['processing_log']\n",
    "#     del ds1['chars']\n",
    "#     ds1.rename({'chars':'band'},inplace=True)\n",
    "#     return ds1.assign_coords(band=1)\n",
    "\n",
    "def pp(ds):\n",
    "    s = ds['image_pair_times'].attrs['mid_date']\n",
    "    ts = pd.Timestamp(s)\n",
    "    ds['time'] = xr.Variable('time', [ts])\n",
    "    return ds\n",
    "\n",
    "m = xr.open_mfdataset(golive2_d + '*.nc', preprocess = pp, decode_cf=False, autoclose=True, concat_dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                                         (chars: 4280, x: 800, y: 786)\n",
       "Coordinates:\n",
       "  * x                                               (x) float64 3.388e+05 ...\n",
       "  * y                                               (y) float64 6.779e+06 ...\n",
       "  * chars                                           (chars) int32 0 1 2 3 4 ...\n",
       "Data variables:\n",
       "    image_pair_times                                |S1 ...\n",
       "    input_image_details                             |S1 ...\n",
       "    transverse_mercator                             |S1 ...\n",
       "    offset_correction                               |S1 ...\n",
       "    applied_bilinear_x_offset_correction_in_pixels  (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    applied_bilinear_y_offset_correction_in_pixels  (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    vx                                              (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    vy                                              (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    vv                                              (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    vx_masked                                       (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    vy_masked                                       (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    vv_masked                                       (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    corr                                            (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    del_corr                                        (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    lgo_mask                                        (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    d2idx2                                          (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    d2jdx2                                          (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    del_i                                           (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    del_j                                           (y, x) float32 dask.array<shape=(786, 800), chunksize=(786, 800)>\n",
       "    processing_log                                  (chars) |S1 dask.array<shape=(4280,), chunksize=(4280,)>\n",
       "Attributes:\n",
       "    GDAL_AREA_OR_POINT:  Area\n",
       "    Conventions:         CF-1.6\n",
       "    history:             2016-11-30T21:02:38.981504 : /projects/makl5454/bin/...\n",
       "    GDAL:                GDAL 2.0.2, released 2016/01/26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2 = xr.open_mfdataset(golive2_d + 'L8_063_018_016_2013_159_2013_175_v1.1.nc')\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2a0d1d662bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgolive2_d\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*.nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_cf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, lock, data_vars, coords, autoclose, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconcat_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_CONCAT_DIM_DEFAULT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             combined = auto_combine(datasets, compat=compat,\n\u001b[0;32m--> 638\u001b[0;31m                                     data_vars=data_vars, coords=coords)\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             combined = auto_combine(datasets, concat_dim=concat_dim,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36mauto_combine\u001b[0;34m(datasets, concat_dim, compat, data_vars, coords)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mconcatenated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(objects, compat, join)\u001b[0m\n\u001b[1;32m    520\u001b[0m         for obj in objects]\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_like_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mcoerced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoerce_pandas_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mexpanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_variable_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/core/alignment.py\u001b[0m in \u001b[0;36mdeep_align\u001b[0;34m(objects, join, copy, indexes, exclude, raise_on_invalid)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     aligned = align(*targets, join=join, copy=copy, indexes=indexes,\n\u001b[0;32m--> 213\u001b[0;31m                     exclude=exclude)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/core/alignment.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(*objects, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0;34m'indexes along dimension {!r} are not equal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                         .format(dim))\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mjoined_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__or__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__xor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2781\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrvals\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2783\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2784\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3244\u001b[0;31m             raise InvalidIndexError('Reindexing only valid with uniquely'\n\u001b[0m\u001b[1;32m   3245\u001b[0m                                     ' valued Index objects')\n\u001b[1;32m   3246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "m = xr.open_mfdataset(golive2_d + '*.nc', decode_cf=False, autoclose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('16.0', '2013.4109589')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(m['image_pair_times'])\n",
    "m['image_pair_times'].del_t, m['image_pair_times'].mid_time_decimal_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm = m.vx_masked\n",
    "vym = m.vy_masked\n",
    "vvm = m.vv_masked\n",
    "corr = m.corr\n",
    "dcorr = m.del_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Cargo Cult; but http://xarray.pydata.org/en/stable/examples/quick-overview.html#create-a-dataarray is a set\n",
    "#   of helpful incremental examples\n",
    "\n",
    "ds=Dataset(data_vars={'acc': '(y, x) float32 dask.array<shape=(828, 819), chunksize=(828, 819)>'}, \\\n",
    "           coords={'* x': 'x yeah', '* y': 'y yeah'}, attrs={'spongy': 'yes'}, compat='broadcast_equals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  ()\n",
       "Coordinates:\n",
       "    * x      <U6 'x yeah'\n",
       "    * y      <U6 'y yeah'\n",
       "Data variables:\n",
       "    acc      <U65 '(y, x) float32 dask.array<shape=(828, 819), chunksize=(828, 819)>' ...\n",
       "Attributes:\n",
       "    spongy:   yes"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
