{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# golive2\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Data summary\n",
    "\n",
    "The notebook continues the **golive** narrative concerning land ice velocities in southeast Alaska, \n",
    "centered around the Malaspina/Seward/Columbus/Bagley/Bering glacier complex.\n",
    "\n",
    "\n",
    "Whereas **golive** used 6 separate time-series results **golive2** \n",
    "improves this to 255 results, again from LANDSAT 8 image pairs from the Path-63 Row-18 frame.\n",
    "The time range is 2013 day 111 (April 21) through 2018 day 269 (September 26); 5.4 years.\n",
    "This gives a mean time spacing of 8 days although the effective spacing will be longer.\n",
    "\n",
    "This appraisal suggests a set of questions/directions\n",
    "\n",
    "- very complete ice motion map using mean values (compared to sparsity of single results)\n",
    "- question: What complementary datasets are available? \n",
    "  - ice thickness? \n",
    "  - surface elevations?\n",
    "    - as these are available: various dynamic calculations are poosible\n",
    "      - volume advection estimates / flux gate views\n",
    "      - sliding speed variability, bed implications\n",
    "- are synthesized datasets worth building / sharing out? \n",
    "  - for example a regularly time-sampled grid of ice speed with NaNs for sparse data \n",
    "  - data reduction results such as standard deviation or (standard deviation / mean)\n",
    "  - Does masking clarify results e.g. by checking velocity direction agreement, invoking `lgo_mask` etc \n",
    "    - lgo_mask varies slightly from one result to the next\n",
    "    - some pixels have unrealistically high velocities (noise)\n",
    "  - What does 2013 speed / mean speed look like? (2013 shows as higher speed on Seward Glacier)\n",
    "\n",
    "- Extension to multiple Landsat 8 frames (addressed in the **golive3** notebook)\n",
    "- Extension to an example region in the Himalayas (**golive4** notebook: S or T 43)\n",
    "\n",
    "\n",
    "#### Surging\n",
    "\n",
    "\n",
    "Inspection of time-series speeds on Seward glacier for the 5.4 year time period considered \n",
    "here shows consistently modest annual variability. Rapid speed-up / slow-down of the glacier ('surging') is \n",
    "not apparent. \n",
    "\n",
    "\n",
    "<img src=\"seward_timeseries.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "\n",
    "However: Surge behavior is apparent in GoLIVE data for late spring 2013 on the glacier just \n",
    "east of Seward which also feeds the Malaspina piedmont. A location is added to the single-point\n",
    "time-series charting cell below to illustrate this, giving: \n",
    "\n",
    "\n",
    "<img src=\"surge_timeseries.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "\n",
    "The multiple observations of fast speed in late spring of 2013 corroborate the surge as a real\n",
    "event. They show the ice moving at 10 meters per day and slowing rapidly towards the quiescent \n",
    "speeds prevalent for most of the five year interval. \n",
    "\n",
    "\n",
    "In contrast the single fast observation in late summer 2017 is uncorroborated and is most\n",
    "likely spurious. This suggests surge detection could be approached in two ways: Viewing a\n",
    "flip book animation or devising a detect/corroborate filter. The animation approach would suffer\n",
    "from the paucity of data in any given frame as the Landsat frame is often obscured by cloud.\n",
    "The filter approach could be more robust and would apply to larger areas; but may require\n",
    "considerable time and effort to design and test.\n",
    "\n",
    "\n",
    "### Methods \n",
    "\n",
    "\n",
    "The source data (speed fields from Landsat 8 image pairs) are bundled in NetCDF files.\n",
    "A traditional approach to working with 255 such results would assign each to a unique\n",
    "`xarray` Dataset; but this would obviate the native ability of xarray to \n",
    "accumulate multi-dimensional data along a new dimension, in this case time. Rather\n",
    "we use here the `xarray.open_mfdataset()` 'open multiple-file dataset' method to treat the\n",
    "entire ensemble together. Spatial bounds expand in so doing to encompass\n",
    "all of the source data. \n",
    "\n",
    "\n",
    "The ice speed scalar field is defined everywhere but meaningful only where the processing\n",
    "algorithm finds a proper correlation. Non-meaningful results include spurious speeds (for\n",
    "example in excess of 20 meters per day in this region) as well as values `-9999.` and `nan`.\n",
    "Ideally we want all such locations to have a value `nan` to support additional calculations\n",
    "such as `.mean()` and `std()` (standard deviation). \n",
    "\n",
    "\n",
    "As noted in **golive**: Within this DataSet the DataArray **Data variable** objects include\n",
    "both scalar speed `vv_masked` and the land/glacier/ocean mask `lgo_mask`. The latter has\n",
    "values at each pixel of 0, 1 or 2 for glacier, land and ocean respectively. The mask can\n",
    "be used in an ad hoc manner to filter speed. Mask values may vary between 0 and 1 from one \n",
    "result to another in the steep terrain of this region.\n",
    "\n",
    "\n",
    "The time-slice data files can be seen along the time axis without loading the data into\n",
    "memory. However this means that time-series analysis across the entire scene will have \n",
    "unacceptable latency as files are repeatedly opened and closed. The `xarray.Dataset.load()` \n",
    "method circumvents this by reading the DataArray into memory whereupon latency drops to \n",
    "negligible. \n",
    "\n",
    "\n",
    "\n",
    "## Part 1. Data loader\n",
    "\n",
    "* Consolidate 255 data files into a single Dataset\n",
    "* load certain DataArrays into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "!pip install utm\n",
    "!pip install pygeotools\n",
    "\n",
    "import timeit\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from ipywidgets import *                # interactivity\n",
    "from traitlets import dlink             # interactivity\n",
    "import sys\n",
    "import os\n",
    "import utm\n",
    "\n",
    "# from osgeo import gdal \n",
    "# from pygeotools.lib import iolib,timelib\n",
    "\n",
    "import golive_utility as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# file grabbing code... this takes a few minutes \n",
    "\n",
    "# because the files are redundant: Use the data directory for the golive3 as the source \n",
    "golive2_d = g.SetDataDirectory('golive3')\n",
    "\n",
    "if False:\n",
    "    ftp = FTP('dtn.rc.colorado.edu')\n",
    "    ftp.login()\n",
    "    ftp.cwd('work/nsidc0710/nsidc0710_landsat8_golive_ice_velocity_v1.1/p063_r018')\n",
    "    a=[]\n",
    "    ftp.dir(a.append)    # This is a rather tricky line of Python as it passes an append method as an argument\n",
    "    d = [b.split()[8] for b in a if len(b.split()) == 9 and b.split()[8][-3:]=='.nc']\n",
    "    for i in range(len(d)):\n",
    "        ftp.retrbinary('RETR ' + d[i], open(golive2_d + d[i], 'wb').write)  \n",
    "        print('obtained file', i)\n",
    "    ftp.quit()\n",
    "    print(len(d))\n",
    "    # for c in d: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Some 16-day and 48-day interval L8 pairs can have the same center time... so we accumulate these center\n",
    "#   times as timestamps in a list. When a redundancy happens: Add an hour to the new one so it does not\n",
    "#   appear simultaneous with the former. Otherwise it is an error in the Dataset compilation. \n",
    "tslist = []\n",
    "\n",
    "def pp(ds):\n",
    "    global tslist\n",
    "    s = ds['image_pair_times'].attrs['mid_date']\n",
    "    ts = pd.Timestamp(s)\n",
    "    while ts in tslist: ts += timedelta(hours = 1)\n",
    "    tslist.append(ts)\n",
    "    ds['time'] = xr.Variable('time', [ts])\n",
    "    return ds\n",
    "\n",
    "# Since a 'time' dimension is added in preprocessing: It can be used as the ordering dimension here\n",
    "m = xr.open_mfdataset(golive2_d + 'L8_063_018*.nc', preprocess = pp, decode_cf=False, autoclose=True, concat_dim='time')\n",
    "\n",
    "# For 255 files this cell requires about 4 minutes\n",
    "print('there are', len(tslist), 'files in play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# print some views of the consolidated dataset 'm'\n",
    "print(len(m['time']), '\\n')\n",
    "print(type(m['time'].values), '\\n')\n",
    "print(m['time'], '\\n')\n",
    "print(m['image_pair_times'], '\\n')\n",
    "print(m['image_pair_times'].time.values[200], '\\n')\n",
    "print(type(m['corr']), '\\n')\n",
    "\n",
    "# load the two primary DataArrays into memory\n",
    "vv = m['vv_masked'].load()\n",
    "lgo = m['lgo_mask'].load()\n",
    "\n",
    "# Adding a third (for example 'corr') may be too memory intensive for this container\n",
    "# corr = m['corr'].load()\n",
    "# north = m['y'].load()\n",
    "# east = m['x'].load()\n",
    "# time = m['time'].load()\n",
    "\n",
    "# This cell takes about 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Complete time-series charts for glacier centerline\n",
    "\n",
    "\n",
    "The xarray DataSet `m` covers the entire time series with DataArrays `vv` (speed) and `lgo` (land/glacier/ocean mask) \n",
    "in memory, plus some additional (corr, north, east). Again this scene is LANDSAT Path 63 Row 18. \n",
    "\n",
    "\n",
    "This section revisits the four transects of Seward Glacier, a medium-sized glacier feeding the Malaspina piedmont lobe.\n",
    "This extends the six-element time series found in the **golive** notebook to the full 255 elements. \n",
    "\n",
    "\n",
    "Some additional deconstruction of the Dataset is included here as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoints determined via map representing four lateral transects of Seward glacier\n",
    "ends = []    # a short list of start/endpoints of transects\n",
    "ends.append(((60.104166,-140.478055),(60.079166,-140.421944)))\n",
    "ends.append(((60.150833,-140.494444),(60.14611,-140.400277)))\n",
    "ends.append(((60.189722,-140.456388),(60.17083,-140.389722)))\n",
    "ends.append(((60.242222,-140.417500),(60.21805,-140.300277)))\n",
    "\n",
    "# An extra transect is added in here: Longitudinal from the Malaspina tributary \n",
    "#   east and south of Seward.\n",
    "#   This tributary moving very fast and decelerating in the spring of 2014; see fifth chart below.\n",
    "#     The same chart also shows a single fast result in late summer 2017; which could be real or spurious.\n",
    "#   Finding this was by chance; it suggests 'surge detection' on a very large scale, restricted only \n",
    "#   by L8 processing latency.\n",
    "ends.append(((60.1,-140.2),(60.0,-140.2)))\n",
    "\n",
    "nTransects = len(ends)\n",
    "tr_idcs = range(nTransects)\n",
    "\n",
    "utm0, utm1 = [], []\n",
    "for i in tr_idcs:\n",
    "    utm0.append(utm.from_latlon(ends[i][0][0],ends[i][0][1]))     # UTM coordinates: x, y, long-band, lat-band\n",
    "    utm1.append(utm.from_latlon(ends[i][1][0],ends[i][1][1]))\n",
    "\n",
    "from numpy.linalg import norm\n",
    "posting = 100.                         # meters between points in the transect\n",
    "\n",
    "# The following lists have index across the various transects\n",
    "transects = [(utm1[i][0]-utm0[i][0], utm1[i][1]-utm0[i][1]) for i in tr_idcs]   # two endpoints of the transect\n",
    "lengths = [norm(transects[i]) for i in tr_idcs]                                 # lengths of those two-endpoint vectors\n",
    "relative_postings = [transects[i]/lengths[i]*posting for i in tr_idcs]          # hop vector for running the transect\n",
    "number_of_postings = [int(lengths[i]/posting) + 1 for i in tr_idcs]             # number of postings (hops) in the transect\n",
    "\n",
    "print(transects, '\\n')\n",
    "print(lengths, '\\n')\n",
    "print(relative_postings, '\\n')\n",
    "print(number_of_postings, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create time-series plots for speeds at the centers of the above four respective lateral transects\n",
    "\n",
    "# Remember that n16s is how many 16-day-interval results we have; and these are m[0], ..., m[n16s - 1]\n",
    "timestamps = vv['time']\n",
    "maxSpeed = 11.\n",
    "colorsequence = ['red', 'orange', 'green', 'cyan', 'black', 'blue', 'yellow']\n",
    "fig, axes = plt.subplots(nTransects)\n",
    "fig.set_size_inches(8,12)\n",
    "for i in tr_idcs: axes[i].set(ylim=(0., maxSpeed), xlabel='time series', ylabel = 'm / d')\n",
    "\n",
    "for t in tr_idcs: \n",
    "    xMid = utm0[t][0] + (number_of_postings[t]/2.)*relative_postings[t][0]    # These must start at utm0 and add a certain \n",
    "    yMid = utm0[t][1] + (number_of_postings[t]/2.)*relative_postings[t][1]    #   number of the relative_postings vectors\n",
    "    y = vv.sel(y=yMid,x=xMid,method='nearest').values \n",
    "    axes[t].plot(timestamps, y, '^', color=colorsequence[t])  \n",
    "    \n",
    "# changing the plot type string from triangles '^' to connected triangles '^-' indicates spurious data:\n",
    "#   -9999 values and errors in speed cause chart lines to dart down / up respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "\n",
    "As noted at the top the Seward time series shows modest cyclic annual variability in speed. This is \n",
    "consistent with the heuristic idea that glaciers accelerate in the spring as melting water (denser\n",
    "than ice) makes its way to the glacier bed, facilitating faster sliding speeds. The shape of the \n",
    "speed profile is coincidentally reminiscent of the Keeling curve tracking atmospheric CO2.\n",
    "\n",
    "\n",
    "<img src=\"keeling.png\" alt=\"drawing\" width=\"450\"/>\n",
    "\n",
    "\n",
    "\n",
    "The fifth chart above, as noted in the *Introduction*, indicates that the glacier east of Seward\n",
    "was moving very fast -- 10 meters per day -- in late spring 2013, rapidly decelerating to a \n",
    "quiescent state. By examining the results around late summer 2017 we see that the single fast\n",
    "speed shown is spurious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell establishes that the lgo_mask varies in time\n",
    "if False:\n",
    "    xice = 702\n",
    "    yice = 402\n",
    "    for i in range(10):                                          # time slices\n",
    "        lgoval = lgo.isel(y=yice,x=xice,time=i).values           # most 0 (glacier) but one 1 (land)\n",
    "        vvval = vv.isel(y=yice,x=xice,time=i).values             # some 'no data' values at -9999.\n",
    "        corrval = corr.isel(y=yice,x=xice,time=i).values         # ranges .51 to .89\n",
    "        northval = north.isel(y=yice).values                     # consistent\n",
    "        eastval = east.isel(x=xice).values                       # consistent\n",
    "        print(lgoval, vvval, corrval, northval, eastval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgo_mask with consecutive times: Slight differences apparent\n",
    "# This makes it intrinsically more difficult to settle on a set of for-sure-this-is-moving-ice pixels\n",
    "if True:\n",
    "    fig,axes = plt.subplots(1, 2)\n",
    "    lgo.isel(time=5).plot(ax=axes[0])\n",
    "    lgo.isel(time=6).plot(ax=axes[1])\n",
    "    fig.set_size_inches(14,6)\n",
    "    axes[0].set(xlim=(540000,570000),ylim=(6670000,6694000))\n",
    "    axes[1].set(xlim=(540000,570000),ylim=(6670000,6694000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgo has both Parameters (particularly 'data') and Attributes (particularly 'values')\n",
    "if False: \n",
    "    print(lgo.data)\n",
    "    print('\\n ------------------- \\n')\n",
    "    print(lgo.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Entire-scene analysis\n",
    "\n",
    "* Using the entire scene is the objective\n",
    "  * Start with a single UTM coordinate: center of first transect shown above\n",
    "  * integer indices? (open challenge)\n",
    "  * Subsets of DataArrays are DataArrays\n",
    "    * ...but .data or .values are numpy ndarrays (immutable vectors)\n",
    "    * 'lists without commas'\n",
    "* Verify no-data value = -9999. and convert these to nan\n",
    "* Use xarray.DataArray.mean(dim) and .std(dim) where dim indicates axis of the calculation\n",
    "  * ...and verify!\n",
    "* Count how many good data values\n",
    "* Count lgo glacier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings but better would be to work out the logic and improve the code so as to not get warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv.to_netcdf('../data/golive3/go_speed.nc')\n",
    "lgo.to_netcdf('../data/golive3/go_lgo.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lgo_mask with consecutive times: Slight differences apparent\n",
    "# This makes it intrinsically more difficult to settle on a set of for-sure-this-is-moving-ice pixels\n",
    "def CompareSnapshotToMean(maxSpeed):\n",
    "    \n",
    "    iceThresholdAdHoc = 0.5\n",
    "    timeSelectAdHoc = 0\n",
    "    \n",
    "    lgo_part1 = lgo.where(lgo.data < 2.)\n",
    "    lgo_part2 = lgo_part1.mean('time')\n",
    "\n",
    "    vv_snap1 = vv.isel(time=timeSelectAdHoc)\n",
    "    vv_snap2 = vv_snap1.where(vv_snap1.data >= 0.)\n",
    "    vv_snap3 = vv_snap2.where(vv_snap2.data <= 14.)\n",
    "    vv_snap4 = vv_snap3.where(lgo_part2.data <= iceThresholdAdHoc)\n",
    "    \n",
    "    vv_mean1=vv.where(vv.data >= 0.)\n",
    "    vv_mean2=vv_mean1.where(vv_mean1.data <= 14.)\n",
    "    vv_mean3=vv_mean2.mean('time')\n",
    "    vv_mean4=vv_mean3.where(lgo_part2.data <= iceThresholdAdHoc)\n",
    "    \n",
    "    fig,axes = plt.subplots(2, 1)\n",
    "    vv_snap4.plot(ax=axes[0],cmap=plt.cm.rainbow,vmin=0.0, vmax=maxSpeed)\n",
    "    vv_mean4.plot(ax=axes[1],cmap=plt.cm.rainbow,vmin=0.0, vmax=maxSpeed)\n",
    "    fig.set_size_inches(14,22)\n",
    "    axes[0].set(xlim=(480000,570000), ylim=(6630000,6694000))\n",
    "    axes[1].set(xlim=(480000,570000), ylim=(6630000,6694000))\n",
    "    \n",
    "    \n",
    "interact(CompareSnapshotToMean, maxSpeed=widgets.FloatSlider(min=0.025, max=20., step=.025, \\\n",
    "                                    value=8.0, continuous_update=False, \\\n",
    "                                    readout_format='1.4f', description='max speed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotSubregion(speed, a, b, c, d, timeSelect, vMax):\n",
    "    fig,axes = plt.subplots()\n",
    "    speed.isel(time=timeSelect).plot(ax=axes,cmap=plt.cm.rainbow,vmin=0.0, vmax=vMax)\n",
    "    fig.set_size_inches(14,8)\n",
    "    axes.set(xlim=(a,c), ylim=(b,d))\n",
    "\n",
    "def go(timeSelector, vMax): \n",
    "    a,c,b,d = 480000,570000,6630000,6694000\n",
    "    PlotSubregion(vv, a, b, c, d, timeSelector, vMax)\n",
    "    \n",
    "interact(go, timeSelector=widgets.IntSlider(min=0,max=254,step=1,value=0, continuous_update=False, description='image index'),       \n",
    "             vMax=widgets.FloatSlider(min=0.05, max=20., step=.025, value=8.0, continuous_update=False, \\\n",
    "                                      readout_format='1.4f', description='max speed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=float('nan')\n",
    "print(a)\n",
    "print(a+a)\n",
    "print(np.isnan(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv1=vv.where(vv.data >= 0.)\n",
    "vv_band_1=vv1.where(vv1.data < 20.)\n",
    "\n",
    "print(vv_band_1.shape)\n",
    "# and lgo.data.any('time')<1.0)\n",
    "\n",
    "def go(timeSelector, vMax): \n",
    "    a,c,b,d = 480000,570000,6630000,6694000\n",
    "    PlotSubregion(vv_band_1, a, b, c, d, timeSelector, vMax)\n",
    "    \n",
    "interact(go, timeSelector=widgets.IntSlider(min=0,max=254,step=1,value=0, continuous_update=False, \\\n",
    "                                            description='image index'),       \n",
    "             vMax=widgets.FloatSlider(min=0.05, max=20., step=.025, value=8.0, continuous_update=False, \\\n",
    "                                      readout_format='1.4f', description='max speed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv2=vv.where(vv.data >= 0.)\n",
    "vv_band_2=vv2.where(vv2.data < 10.)\n",
    "\n",
    "def go(timeSelector, vMax): \n",
    "    a,c,b,d = 480000,570000,6630000,6694000\n",
    "    PlotSubregion(vv_band_2, a, b, c, d, timeSelector, vMax)\n",
    "    \n",
    "interact(go, timeSelector=widgets.IntSlider(min=0,max=254,step=1,value=0, continuous_update=False, \\\n",
    "                                            description='image index'),       \n",
    "             vMax=widgets.FloatSlider(min=0.05, max=20., step=.025, value=8.0, continuous_update=False, \\\n",
    "                                      readout_format='1.4f', description='max speed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv1=vv.where(vv.data >= 0.).mean('time')\n",
    "vv2=vv.where(vv.data >= 0.).std('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv.isel(time=0).plot()\n",
    "fig.set_size_inches(14,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv1.plot()\n",
    "fig.set_size_inches(14,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vv1.isel(x=537,y=319).data)\n",
    "print(vv2.isel(x=537,y=319).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv3=vv2/vv1\n",
    "vv3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv4 = vv3.where(vv3.data < 2.0)\n",
    "vv5 = vv4.where(vv4.data > 0.05)\n",
    "vv6 = vv5.where(lgo4.data >= 0.0)\n",
    "vv6.plot(figsize=(14,10),cmap=plt.cm.rainbow,vmin=0.05, vmax=2.0)\n",
    "plt.xlim(440000,550000)\n",
    "plt.ylim(6630000,6730000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvlgo1 = vv1.where(lgo4.data >= 0.)\n",
    "vvlgo1.plot(figsize=(14,10),cmap=plt.cm.rainbow,vmin=0.05, vmax=2.0)\n",
    "plt.xlim(440000,550000)\n",
    "plt.ylim(6630000,6730000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
