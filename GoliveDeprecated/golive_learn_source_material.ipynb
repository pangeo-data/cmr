{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjuration\n",
    "\n",
    "There really does not seem to this author to be a fast path to using `xarray`. At some point the novice must\n",
    "set aside other concerns and just spend time methodically going through Datasets and DataArrays in detail. The\n",
    "following code does this; not exahaustively but in sufficient detail to suggest further tests and trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utm in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pygeotools in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: gdal in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->pygeotools)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->pygeotools)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "!pip install utm\n",
    "!pip install pygeotools\n",
    "\n",
    "import timeit\n",
    "from datetime import timedelta, datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "from numpy import datetime64 as dt64, timedelta64 as td64\n",
    "from scipy import stats\n",
    "from scipy.signal import medfilt as mf\n",
    "from random import randint as ri\n",
    "\n",
    "from ipywidgets import *                # interactivity\n",
    "from traitlets import dlink             # interactivity\n",
    "import sys\n",
    "import os\n",
    "import utm\n",
    "\n",
    "# from osgeo import gdal \n",
    "# from pygeotools.lib import iolib,timelib\n",
    "\n",
    "import golive_utility as g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataArray to Dataset with manipulations\n",
    "\n",
    "Often we begin with a `NetCDF` file which is loaded as a `Dataset`. This is found wanting in \n",
    "some regard so we are confronted with the task of modifying it. Such `Datasets` can be seen as \n",
    "sets of `xarray DataArrays` which in turn have four components: Attributes, Coordinates, Dimensions\n",
    "and then the Data itself. \n",
    "\n",
    "The objective here is to avoid the 'load a file' approach and instead create an `xarray DataArray` from \n",
    "scratch. Then we modify it; and then convert it to an `xarray Dataset`; and then modify *that*. I believe\n",
    "that the originators encourage us to modify by creating new objects, in contrast to modification in \n",
    "place; i.e. `foo1 = foo.modifiers`.\n",
    "\n",
    "The methods used here are not comprehensive and a more thorough progression may be found \n",
    "[here](http://xarray.pydata.org/en/stable/indexing.html) and on related `xarray` documentation pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo is\n",
      " <xarray.DataArray 'AmeliaBedelia' (time: 4, space: 3)>\n",
      "array([[0.333109, 0.676326, 0.038695],\n",
      "       [0.053559, 0.118535, 0.456464],\n",
      "       [0.481033, 0.653377, 0.419931],\n",
      "       [0.947168, 0.881157, 0.648001]])\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "  * space    (space) <U2 'WA' 'OR' 'CA'\n",
      "Attributes:\n",
      "    Here:        We\n",
      "    Include:     Metatada\n",
      "    Attributes:  As a dictionary\n",
      "    throw in:    some meters\n"
     ]
    }
   ],
   "source": [
    "# from the documentation: A sequence of operations on a DataArray showing some finesse points\n",
    "#   - using numpy to generate random 2D array\n",
    "#   - a spatial coordinate can have labels that are string\n",
    "#   - pandas generates a date sequence with default day intervals\n",
    "#   - declaring a DataArray\n",
    "#     - providing data\n",
    "#     - providing coordinates\n",
    "#     - providing dimensions\n",
    "#     - providing a name\n",
    "#     - providing attributes\n",
    "#   - adding another attribute\n",
    "#   - changing the name: Producing a new DataArray; not in-place\n",
    "\n",
    "rdata = np.random.rand(4, 3)                        # a 2D ndarray of random values with dimensions as given\n",
    "locs = ['WA', 'OR', 'CA']                           # three state abbreviations\n",
    "times = pd.date_range('2000-01-01', periods=4)      # default period is 1 day \n",
    "foo = xr.DataArray(rdata, coords=[times, locs],     # first argument is always the data\n",
    "    dims=['time', 'space'],                         # data, coordinates, dimensions and attributes are de rigeur\n",
    "    attrs={'Here': 'We', 'Include': 'Metatada',     #   where only data is actually required as the first argument\n",
    "          'Attributes': 'As a dictionary'},         # It would be more typical to build the dictionary in advance\n",
    "    name='Amelia')                                  # This name Amelia associates with the data, not the DataArray object\n",
    "                                                    #   which is of course 'foo'\n",
    "                   \n",
    "foo.attrs['throw in'] = 'some meters'               # expand an existing attributes Dictionary\n",
    "\n",
    "foo = foo.rename('AmeliaBedelia')                   # 'rename()' returns a new DataArray without modifying foo\n",
    "                                                    #   so we re-assign the new object to foo. Notice this action\n",
    "                                                    #   can't be done in-place with foo.rename('AmeliaBedelia') as\n",
    "                                                    #   this leaves foo unchanged\n",
    "print('foo is\\n', foo)                              # notice that 'rdata' is not mentioned but AmeliaBedelia is. If\n",
    "                                                    #   no name had been given this label would be omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
      "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
      "Data variables:\n",
      "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648 \n",
      "\n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:              (space: 3)\n",
      "Coordinates:\n",
      "  * space                (space) <U2 'WA' 'OR' 'CA'\n",
      "Data variables:\n",
      "    2000-01-01 00:00:00  (space) float64 0.3331 0.6763 0.0387\n",
      "    2000-01-02 00:00:00  (space) float64 0.05356 0.1185 0.4565\n",
      "    2000-01-03 00:00:00  (space) float64 0.481 0.6534 0.4199\n",
      "    2000-01-04 00:00:00  (space) float64 0.9472 0.8812 0.648\n",
      "Attributes:\n",
      "    Here:        We\n",
      "    Include:     Metatada\n",
      "    Attributes:  As a dictionary\n",
      "    throw in:    some meters \n",
      "\n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:  (time: 4)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "Data variables:\n",
      "    WA       (time) float64 0.3331 0.05356 0.481 0.9472\n",
      "    OR       (time) float64 0.6763 0.1185 0.6534 0.8812\n",
      "    CA       (time) float64 0.0387 0.4565 0.4199 0.648\n",
      "Attributes:\n",
      "    Here:        We\n",
      "    Include:     Metatada\n",
      "    Attributes:  As a dictionary\n",
      "    throw in:    some meters\n"
     ]
    }
   ],
   "source": [
    "foo1 = foo.to_dataset()\n",
    "foo2 = foo.to_dataset(dim='time')\n",
    "foo3 = foo.to_dataset(dim='space')\n",
    "print(foo1, '\\n\\n\\n', foo2, '\\n\\n\\n', foo3)  # The DataArray transforms into a Dataset in three ways\n",
    "                                             # foo1: retains the DataArray as a Dataset Data variable named \n",
    "                                             #   AmeliaBedelia with time (4 elements) and space (3) as dimensions\n",
    "                                             #   matched to coordinates. Thus the Data variable is indexed in these \n",
    "                                             #   two dimensions. Attributes of foo do not appear as Dataset attributes\n",
    "                                             #   but they are still present as attributes of Data variable 'AmeliaBedelia'.\n",
    "                                             # foo2: The 'time' dimension is named for Data variable decomposition\n",
    "                                             #   whereupon each of the four time elements (coordinate values) becomes a \n",
    "                                             #   Data variable of that name (2001-01-01 etcetera). Each such data \n",
    "                                             #   variable retains its three spatial values which remains a dimension\n",
    "                                             #   linked to a coordinate. Attributes of foo are detached from \n",
    "                                             #   AmeliaBedelia (which does not exist in foo2) and promoted to be\n",
    "                                             #   attributes of the Dataset.\n",
    "                                             # foo3: Same as foo2 but using 'space' to break apart the source DataArray\n",
    "# print('\\n\\n\\n', foo) will confirm that foo is unchanged by all the above\n",
    "# print('\\n\\n\\n', foo1.AmeliaBedelia.attrs) will confirm that foo1 retains foo attributes under Data variable AmeliaBedelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (space: 3, time: 4)\n",
       "Coordinates:\n",
       "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
       "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
       "Data variables:\n",
       "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
       "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
       "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding additional Data variables is done using the syntax xr.Dataset['newDatavariable']=(,)\n",
    "# \n",
    "# Continuing with the foo1 'AmeliaBedelia' Dataset where two dimensions/coordinates 'space' and 'time' are retained:\n",
    "#   Add two Data variables 'temp' and 'precip' using existing dimensions. These Data variables are assigned as tuples\n",
    "#   where the first argument is (itself a tuple of) coordinates/dimensions and the second is a numpy ndarray of random\n",
    "#   values that matches the implicit shape. The order of coordinates is retained in the Dataset organization.\n",
    "\n",
    "# Add two Data variables\n",
    "foo1['temp'] = (('time', 'space'), np.random.rand(4, 3))\n",
    "foo1['precip'] = (('space', 'time'), np.random.rand(3,4)*5.)\n",
    "foo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (eastspace: 3, space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
      "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
      "  * eastspace      (eastspace) <U2 'GA' 'NC' 'SC'\n",
      "Data variables:\n",
      "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
      "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
      "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192\n"
     ]
    }
   ],
   "source": [
    "# Now that we can add new Data variables let's re-assign their coordinates/dimensions\n",
    "#   First let's add a new coordinate/dimension. Similar to the above we now stipulate\n",
    "#   '.coords'\n",
    "foo1.coords['eastspace']=('eastspace', ['GA', 'NC', 'SC'])\n",
    "print(foo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (eastspace: 3, space: 3, time: 4)\n",
       "Coordinates:\n",
       "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
       "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
       "  * eastspace      (eastspace) <U2 'GA' 'NC' 'SC'\n",
       "Data variables:\n",
       "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
       "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
       "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192\n",
       "    NewAmelia      (time, eastspace) float64 0.3331 0.6763 ... 0.8812 0.648"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is unclear whether coordinates can be re-assigned to a Data variable in place. However\n",
    "# at this point I have sufficient tools to create a new Data variable within the foo1 Dataset \n",
    "# that takes its values from an existing Data variable; with new coordinates as follows.\n",
    "foo1['NewAmelia']=(('time','eastspace'), foo1.AmeliaBedelia)\n",
    "foo1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermezzo on culling down Datasets\n",
    "\n",
    "It came to my attention that a double-square-bracket mechanism would\n",
    "produce a new Dataset from existing with only some Data variables preserved; as in foo1[['temp']] in\n",
    "the present example. I will explore this a bit primarily by freely pasting/modifying from the\n",
    "[xarray documentation on data structures](http://xarray.pydata.org/en/stable/data-structures.html). \n",
    "\n",
    "\n",
    "> In addition to dictionary-like methods, xarray has panda-like methods for transforming datasets. For removing \n",
    "variables, you can select/drop an explicit list of variables by indexing with a list of Data variable names.\n",
    "You can also use the drop() method to return a new Dataset. These operations keep around coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp', 'space', 'time']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")     # suppress some annoying warnings\n",
    "list(foo1[['temp']])                                   # gives the Data variable and its dependencies (coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foo1[[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['space']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foo1[['space']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (space: 3)\n",
       "Coordinates:\n",
       "  * space    (space) <U2 'WA' 'OR' 'CA'\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo1[['space']]            # demonstrates how the [['coordinate_name']] operation produces a new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time', 'space', 'AmeliaBedelia', 'precip', 'eastspace', 'NewAmelia']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foo1.drop('temp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time', 'space', 'AmeliaBedelia', 'temp', 'precip', 'eastspace']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foo1.drop('NewAmelia'))        # notice this retains 'eastspace' even though it is not longer in use\n",
    "                                    # 'eastspace' could subsequently be dropped as a separate step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'NewAmelia' (time: 4, eastspace: 3)>\n",
      "array([[0.333109, 0.676326, 0.038695],\n",
      "       [0.053559, 0.118535, 0.456464],\n",
      "       [0.481033, 0.653377, 0.419931],\n",
      "       [0.947168, 0.881157, 0.648001]])\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "  * eastspace  (eastspace) <U2 'GA' 'NC' 'SC' \n",
      "\n",
      "\n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:        (eastspace: 3, space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
      "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
      "Dimensions without coordinates: eastspace\n",
      "Data variables:\n",
      "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
      "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
      "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192\n",
      "    NewAmelia      (time, eastspace) float64 0.3331 0.6763 ... 0.8812 0.648 \n",
      "\n",
      "\n",
      " <xarray.DataArray 'NewAmelia' (time: 4, eastspace: 3)>\n",
      "array([[0.333109, 0.676326, 0.038695],\n",
      "       [0.053559, 0.118535, 0.456464],\n",
      "       [0.481033, 0.653377, 0.419931],\n",
      "       [0.947168, 0.881157, 0.648001]])\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "Dimensions without coordinates: eastspace\n"
     ]
    }
   ],
   "source": [
    "print(foo1.NewAmelia, '\\n\\n\\n')\n",
    "foo1_DES = foo1.drop('eastspace')              # This runs but invites trouble as 'NewAmelia' depends upon 'eastspace'\n",
    "print(foo1_DES, '\\n\\n\\n', foo1_DES.NewAmelia)  # Dropping 'eastspace' removes it from coordinates but not dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (eastspace: 3, space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
      "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
      "  * eastspace      (eastspace) <U2 'GA' 'NC' 'SC'\n",
      "Data variables:\n",
      "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
      "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
      "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192 \n",
      "\n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:        (space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
      "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
      "Data variables:\n",
      "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
      "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
      "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192\n"
     ]
    }
   ],
   "source": [
    "foo1_DNA = foo1.drop('NewAmelia')\n",
    "print(foo1_DNA, '\\n\\n\\n', foo1_DNA.drop('eastspace'))     # Now 'eastspace' is neither a coordinate nor a dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternate to dictionary-like modifications we can use assign() and assign_coords(). \n",
    "These methods return a new dataset with additional (or replaced) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (eastspace: 3, space: 3, time: 4)\n",
       "Coordinates:\n",
       "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
       "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
       "  * eastspace      (eastspace) <U2 'GA' 'NC' 'SC'\n",
       "Data variables:\n",
       "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
       "    temp           (time, space) float64 0.4994 0.5133 0.1545 ... 0.661 0.785\n",
       "    precip         (space, time) float64 0.7685 0.8414 4.721 ... 0.3093 1.192\n",
       "    NewAmelia      (time, eastspace) float64 0.3331 0.6763 ... 0.8812 0.648\n",
       "    temp2          (time, space) float64 0.9988 1.027 0.309 ... 1.322 1.57"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo1.assign(temp2 = 2 * foo1.temp)   # creates a new Data variable temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (lon: 4)>\n",
      "array([0.09482 , 0.368684, 0.916153, 0.611832])\n",
      "Coordinates:\n",
      "  * lon      (lon) int64 358 359 0 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (lon: 4)>\n",
       "array([0.09482 , 0.368684, 0.916153, 0.611832])\n",
       "Coordinates:\n",
       "  * lon      (lon) int64 -2 -1 0 1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = xr.DataArray(np.random.rand(4), coords=[np.array([358, 359, 0, 1])], dims='lon')\n",
    "print(da)\n",
    "da.assign_coords(lon=(((da.lon + 180) % 360) - 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen(OrderedDict([('time', <xarray.IndexVariable 'time' (time: 4)>\n",
      "array(['2000-01-01T00:00:00.000000000', '2000-01-02T00:00:00.000000000',\n",
      "       '2000-01-03T00:00:00.000000000', '2000-01-04T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')), ('space', <xarray.IndexVariable 'space' (space: 3)>\n",
      "array(['WA', 'OR', 'CA'], dtype='<U2')), ('AmeliaBedelia', <xarray.Variable (time: 4, space: 3)>\n",
      "array([[0.333109, 0.676326, 0.038695],\n",
      "       [0.053559, 0.118535, 0.456464],\n",
      "       [0.481033, 0.653377, 0.419931],\n",
      "       [0.947168, 0.881157, 0.648001]])\n",
      "Attributes:\n",
      "    Here:        We\n",
      "    Include:     Metatada\n",
      "    Attributes:  As a dictionary\n",
      "    throw in:    some meters), ('temp', <xarray.Variable (time: 4, space: 3)>\n",
      "array([[0.386323, 0.316881, 0.805549],\n",
      "       [0.548601, 0.539673, 0.546998],\n",
      "       [0.441486, 0.726055, 0.216722],\n",
      "       [0.980658, 0.643383, 0.060856]])), ('precip', <xarray.Variable (space: 3, time: 4)>\n",
      "array([[4.922374, 3.173554, 1.285075, 3.717247],\n",
      "       [1.193583, 0.531211, 1.716011, 3.177487],\n",
      "       [2.818774, 0.797361, 1.233815, 3.125993]])), ('eastspace', <xarray.IndexVariable 'eastspace' (eastspace: 3)>\n",
      "array(['GA', 'NC', 'SC'], dtype='<U2')), ('NewAmelia', <xarray.Variable (time: 4, eastspace: 3)>\n",
      "array([[0.333109, 0.676326, 0.038695],\n",
      "       [0.053559, 0.118535, 0.456464],\n",
      "       [0.481033, 0.653377, 0.419931],\n",
      "       [0.947168, 0.881157, 0.648001]]))]))\n"
     ]
    }
   ],
   "source": [
    "foo_sidebar = foo1\n",
    "#list(foo_sidebar[['NewAmelia']])\n",
    "print(foo_sidebar.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To continue with the Data variable culling\n",
    "\n",
    "Taking advantage of the above intermezzo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (eastspace: 3, space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2000-01-04\n",
      "  * space          (space) <U2 'WA' 'OR' 'CA'\n",
      "  * eastspace      (eastspace) <U2 'GA' 'NC' 'SC'\n",
      "Data variables:\n",
      "    AmeliaBedelia  (time, space) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n",
      "    temp           (time, space) float64 0.3863 0.3169 0.8055 ... 0.6434 0.06086\n",
      "    precip         (space, time) float64 4.922 3.174 1.285 ... 1.234 3.126\n",
      "    NewAmelia      (time, eastspace) float64 0.3331 0.6763 ... 0.8812 0.648 \n",
      "\n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:    (eastspace: 3, space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * space      (space) <U2 'WA' 'OR' 'CA'\n",
      "  * eastspace  (eastspace) <U2 'GA' 'NC' 'SC'\n",
      "  * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "Data variables:\n",
      "    temp       (time, space) float64 0.3863 0.3169 0.8055 ... 0.6434 0.06086\n",
      "    precip     (space, time) float64 4.922 3.174 1.285 ... 0.7974 1.234 3.126\n",
      "    NewAmelia  (time, eastspace) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648 \n",
      "\n",
      "\n",
      " <xarray.Dataset>\n",
      "Dimensions:    (eastspace: 3, time: 4)\n",
      "Coordinates:\n",
      "  * eastspace  (eastspace) <U2 'GA' 'NC' 'SC'\n",
      "  * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "Data variables:\n",
      "    NewAmelia  (time, eastspace) float64 0.3331 0.6763 0.0387 ... 0.8812 0.648\n"
     ]
    }
   ],
   "source": [
    "# Let's reduce foo1 to foo1r by getting rid of 'AmeliaBedelia' as it is just confusing clutter.\n",
    "foo1r=foo1[['temp','precip','NewAmelia']]\n",
    "# Then let's get rid of temp and precip to see whether this also eliminates the 'space' coordinate\n",
    "foo1s=foo1r[['NewAmelia']]\n",
    "print(foo1, '\\n\\n\\n', foo1r, '\\n\\n\\n', foo1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unresolved issues\n",
    "\n",
    "Need to explain how this works... I believe to introduce a new Data variable to ds\n",
    "\n",
    "\n",
    "`ds['time'] = xr.Variable('time', [ts])`\n",
    "\n",
    "\n",
    "Need a working example of adding a 1-element additional dimension using...\n",
    "\n",
    "\n",
    "`ds.expand_dims('new_dim_name')` \n",
    "\n",
    "and why this is useful (can make multiple datasets combinable)\n",
    "\n",
    "### Moving on to coordinate and dimension manipulations \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (dope: 4, latitude: 24, longitude: 18, moped: 5, q: 1, space: 3)\n",
       "Coordinates:\n",
       "  * space                (space) <U2 'WA' 'OR' 'CA'\n",
       "    lat                  (latitude) float64 0.0 1.0 2.0 3.0 ... 21.0 22.0 23.0\n",
       "    lon                  (longitude) float64 0.0 1.0 2.0 3.0 ... 15.0 16.0 17.0\n",
       "  * q                    (q) float64 1.4\n",
       "    q2                   float64 1.5\n",
       "  * moped                (moped) int64 0 1 2 3 4\n",
       "    reference_time       datetime64[ns] 2014-09-05\n",
       "  * dope                 (dope) datetime64[ns] 2000-01-01 ... 2000-01-04\n",
       "Dimensions without coordinates: latitude, longitude\n",
       "Data variables:\n",
       "    2000-01-01 00:00:00  (space) float64 0.3331 0.6763 0.0387\n",
       "    2000-01-02 00:00:00  (space) float64 0.05356 0.1185 0.4565\n",
       "    2000-01-03 00:00:00  (space) float64 0.481 0.6534 0.4199\n",
       "    2000-01-04 00:00:00  (space) float64 0.9472 0.8812 0.648\n",
       "Attributes:\n",
       "    Here:        We\n",
       "    Include:     Metatada\n",
       "    Attributes:  As a dictionary\n",
       "    throw in:    some meters"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add two coordinates that will be non-dimensional\n",
    "fubar = foo.to_dataset(dim='time')\n",
    "fubar\n",
    "\n",
    "fubar.coords['lat'] = ('latitude', np.arange(24.))               # implicitly declares dimension latitude\n",
    "fubar.coords['lon'] = ('longitude', np.arange(18.))              #   and longitude. Since these are not the\n",
    "                                                                 #   same as the coordinate names 'lat' and 'lon'\n",
    "                                                                 #   these coords are 'non-dimension coordinates'\n",
    "        \n",
    "# As there are not coords matching dims 'latitude' and 'longitude' they become 'Dimensions without coordinates'.\n",
    "# 'time' is a former dimension, discontinued when fubar was created with: fubar=foo.to_dataset(dim='time'). \n",
    "# Since this broke the AmeliaBedelia data up by time into multiple DataArrays the time dimension went away.\n",
    "\n",
    "\n",
    "# Here are additional 'coordinate addition' experiments\n",
    "fubar.coords['q'] = (('q', [1.4]))                               # list notation implies (coordinate + dimension)\n",
    "fubar.coords['q2'] = 1.5                                         # single value fails to imply and therefore \n",
    "                                                                 #   fails to create dimension 'q2' but the \n",
    "                                                                 #   coordinate 'q2' is created\n",
    "fubar.coords['moped'] = np.arange(5)                             # multiple values imply and create dimension 'moped'\n",
    "fubar.coords['reference_time'] = pd.Timestamp('2014-09-05')      # Single value: No dimension implied\n",
    "fubar.coords['dope'] = pd.date_range('2000-01-01', periods=4)    # Multiple values: Dimension of same name implied\n",
    "\n",
    "fubar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (dope: 4, latitude: 24, longitude: 18, moped: 5, q: 1, space: 3)\n",
       "Coordinates:\n",
       "  * space                (space) <U2 'WA' 'OR' 'CA'\n",
       "    lat                  (latitude) float64 0.0 1.0 2.0 3.0 ... 21.0 22.0 23.0\n",
       "    lon                  (longitude) float64 0.0 1.0 2.0 3.0 ... 15.0 16.0 17.0\n",
       "  * q                    (q) float64 1.4\n",
       "    q2                   float64 1.5\n",
       "  * moped                (moped) int64 0 1 2 3 4\n",
       "    reference_time       datetime64[ns] 2014-09-05\n",
       "  * dope                 (dope) datetime64[ns] 2000-01-01 ... 2000-01-04\n",
       "Dimensions without coordinates: latitude, longitude\n",
       "Data variables:\n",
       "    2000-01-01 00:00:00  (space) float64 0.3331 0.6763 0.0387\n",
       "    2000-01-02 00:00:00  (space) float64 0.05356 0.1185 0.4565\n",
       "    2000-01-03 00:00:00  (space) float64 0.481 0.6534 0.4199\n",
       "    2000-01-04 00:00:00  (space) float64 0.9472 0.8812 0.648\n",
       "Attributes:\n",
       "    Here:         is a change\n",
       "    Include:      Metatada\n",
       "    Attributes:   As a dictionary\n",
       "    throw in:     some meters\n",
       "    throwing in:  another attribute\n",
       "    perhaps:      these appear in arbitrary order"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attr modification\n",
    "\n",
    "fubar.attrs['throwing in'] = 'another attribute'\n",
    "fubar.attrs['Here'] = 'is a change'\n",
    "fubar.attrs['perhaps'] = 'these appear in arbitrary order'\n",
    "\n",
    "fubar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- T no parens; Transpose by reversing order of dimensions\n",
    "\n",
    "- argmax\n",
    "- argmin\n",
    "- argsort\n",
    "- assign_attrs\n",
    "- assign_coords\n",
    "- astype\n",
    "- attrs\n",
    "- bfill\n",
    "- broadcast_equals\n",
    "- chunk\n",
    "- chunks\n",
    "- clip\n",
    "- close\n",
    "- combine_first\n",
    "- compute\n",
    "- conj\n",
    "- conjugate\n",
    "- coords\n",
    "- copy\n",
    "- count\n",
    "- cumprod\n",
    "- cumsum\n",
    "- data\n",
    "- diff\n",
    "- differentiate\n",
    "- dims\n",
    "- dot\n",
    "- drop\n",
    "\n",
    "\n",
    "### `dropna()` gets its own section \n",
    "\n",
    "\n",
    "- dropna() gets its own section\n",
    "\n",
    "\n",
    "### to continue...\n",
    "\n",
    "- dt\n",
    "- dtype\n",
    "- encoding\n",
    "- equals\n",
    "- expand_dims\n",
    "- ffill\n",
    "- fillna\n",
    "- from_cdms2\n",
    "- from_dict\n",
    "- from_iris\n",
    "- from_series\n",
    "- get_axis_num\n",
    "- get_index\n",
    "- groupby\n",
    "- groupby_bins\n",
    "- identical\n",
    "- imag\n",
    "- indexes\n",
    "- interp\n",
    "- interp_like\n",
    "- interpolate_na\n",
    "\n",
    "- isin\n",
    "- isnull\n",
    "- item\n",
    "- load\n",
    "- loc\n",
    "- max\n",
    "- mean\n",
    "- median\n",
    "- min\n",
    "- name\n",
    "- nbytes\n",
    "- ndim\n",
    "- notnull\n",
    "- persist\n",
    "- pipe\n",
    "- plot\n",
    "- prod\n",
    "- quantile\n",
    "- rank\n",
    "- real\n",
    "- reduce\n",
    "- reindex\n",
    "- reindex_like\n",
    "- rename\n",
    "- reorder_levels\n",
    "- resample\n",
    "- reset_coords\n",
    "- reset_index\n",
    "- roll\n",
    "- rolling\n",
    "- round\n",
    "- searchsorted\n",
    "\n",
    "- set_index\n",
    "- shape\n",
    "- shift\n",
    "- size\n",
    "- sizes\n",
    "- sortby\n",
    "- squeeze\n",
    "- stack\n",
    "- std\n",
    "- sum\n",
    "- swap_dims\n",
    "- to_cdms2\n",
    "- to_dataframe\n",
    "- to_dataset\n",
    "- to_dict\n",
    "- to_index\n",
    "- to_iris()\n",
    "- to_masked_array()\n",
    "- to_netcdf()\n",
    "- to_pandas()\n",
    "- to_series()\n",
    "- transpose()\n",
    "- unstack()\n",
    "- values()\n",
    "- var()\n",
    "- variable()\n",
    " \n",
    " #### Also found in Dataset\n",
    " \n",
    "- all()\n",
    "- any()\n",
    "- isel\n",
    "- isel_points()\n",
    "- sel\n",
    "- sel_points\n",
    "- where()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Continuing with `dads` attributes (methods and state variables)\n",
    "\n",
    "#### State attributes specific to this particular *`dads`* Dataset\n",
    "\n",
    "\n",
    "- `tt, xx, yy` are both coordinates and dimensions within `dads`. In this context they are *coordinates*, not *dimensions*.\n",
    "- `speedfield` is a Data variable within `dads`\n",
    "\n",
    "`'tt' in dads and 'speedfield' in dads # prints True`\n",
    "\n",
    "#### Modify Dataset structure\n",
    "\n",
    "- set_coords(string or list of strings)             migrates named Data variable(s) into Coordinates\n",
    "\n",
    "\n",
    "#### Selection and comparison methods\n",
    "\n",
    "\n",
    "- where()\n",
    "- all()\n",
    "- any()\n",
    "- isel()\n",
    "- sel()\n",
    "\n",
    "\n",
    "#### Format and file methods\n",
    "\n",
    "- to_array\n",
    "- to_dask_dataframe\n",
    "- to_dataframe\n",
    "- to_dict\n",
    "- to_netcdf\n",
    "- to_zarr\n",
    "- load\n",
    "\n",
    "#### `dask.array` chunking\n",
    "\n",
    "- chunk\n",
    "- chunks\n",
    "\n",
    "\n",
    "#### four categories of content of a Dataset (objects with their own attributes)\n",
    "\n",
    "- .attrs\n",
    "- .coords\n",
    "- .data_vars\n",
    "- .dims\n",
    "\n",
    "\n",
    "#### assessing content\n",
    "\n",
    "- count\n",
    "\n",
    "\n",
    "#### selecting content\n",
    "\n",
    "\n",
    "\n",
    "#### Sir Not-yet-summarized methods\n",
    "\n",
    "- apply\n",
    "- argmax\n",
    "- argmin\n",
    "- argsort\n",
    "- assign\n",
    "- assign_attrs\n",
    "- assign_coords\n",
    "- astype\n",
    "- bfill\n",
    "- broadcast_equals\n",
    "- clip\n",
    "- close\n",
    "- combine_first\n",
    "- compute\n",
    "- conj\n",
    "- conjugate \n",
    "- copy\n",
    "- cumprod\n",
    "- cumsum\n",
    "- diff\n",
    "- differentiate\n",
    "- drop\n",
    "- dropna\n",
    "\n",
    "- dump_to_store\n",
    "- encoding\n",
    "- equals\n",
    "- expand_dims\n",
    "- ffill\n",
    "- fillna\n",
    "- filter_by_attrs\n",
    "- from_dataframe\n",
    "- from_dict\n",
    "- get\n",
    "- get_index\n",
    "- groupby\n",
    "- groupby_bins\n",
    "- identical\n",
    "- imag\n",
    "- indexes\n",
    "- info\n",
    "- interp\n",
    "- interp_like\n",
    "- interpolate_na\n",
    "- isel_points \n",
    "- isin\n",
    "- isnull\n",
    "- items\n",
    "- keys\n",
    "- load_store\n",
    "- loc\n",
    "- max\n",
    "- mean\n",
    "- median\n",
    "- merge\n",
    "- min\n",
    "- nbytes\n",
    "- notnull\n",
    "- persist\n",
    "- pipe\n",
    "- prod\n",
    "- quantile\n",
    "- rank\n",
    "- real\n",
    "- reduce\n",
    "- reindex\n",
    "- reindex_like\n",
    "- rename() will rename Data variables returning a new Dataset; not 'in place'\n",
    "- reorder_levels\n",
    "- resample\n",
    "- reset_coords\n",
    "- reset_index\n",
    "- roll\n",
    "- rolling\n",
    "- round\n",
    "- sel_points\n",
    "- set_index\n",
    "- shift\n",
    "- sizes\n",
    "- sortby\n",
    "- squeeze\n",
    "- stack\n",
    "- std\n",
    "- sum\n",
    "- swap_dims() swaps a dimensional for a non-dimensional coordinate\n",
    "- transpose\n",
    "- unstack\n",
    "- update\n",
    "- values\n",
    "- var\n",
    "- variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dads` DataArray Dataset\n",
    "\n",
    "* We start with a 3D ndarray `cube`\n",
    "* Cast this as a dask array\n",
    "* Cast this as a DataArray\n",
    "* Cast this as an xr.Dataset `dads`\n",
    "\n",
    "\n",
    "### The Dataset summarized\n",
    "\n",
    "\n",
    "`print(dir(dads))` produces a vast list of state attributes and method attributes (110 of them!)\n",
    "These are sorted out here as an exercise in gaining familiarity with xarray Datasets. At the top level \n",
    "a Dataset is composed of four objects:\n",
    "\n",
    "- An OrderedDict of attributes\n",
    "- Dataset coordinates: Analogous to a key:value Dictionary of DataArrays.\n",
    "- Dataset dimensions (which are 'Frozen')\n",
    "- DataVariables containing data distributed across some of these dimensions, optionally using the coordinates\n",
    "\n",
    "\n",
    "These four objects are instances of four classes; so each has its own attributes; and \n",
    "so on down into various weeds. At the moment we are interested in this high level of the `dads` Dataset: \n",
    "I indicate methods in what follows using `.method(arg[s])` with some examples.  \n",
    "\n",
    "\n",
    "#### Related terminology\n",
    "\n",
    "- Python Mapping is an important construct in the design of this machinery (stub remark).\n",
    "- methods: method functions are declared within a class with an explicit first argument representing that \n",
    "object (the Dataset) which is provided implicitly by the method call; so the method has access to the \n",
    "entirety of the Dataset object, referring to it as `self`.\n",
    "- `xr.DataArray` also has four components: `values`, `dims`, `coords`, and `attrs`. `dims` are analogous to\n",
    "an `axis` in numpy. (A DataArray can also optionally be assigned a `name`: `fu = xr.DataArray(data=3, name='bar')`.\n",
    "- `dask` builds graph representations for dynamic task scheduling needed to perform out-of-core computations. It mimics `Pandas` DataFrames by having its own DataFrames and likewise mimics the `np.ndarray` via `dask.array`; with the \n",
    "user-crucial addition of the concept of the chunk. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<getitem, shape=(), dtype=float64, chunksize=()>\n",
      "dask.array<array, shape=(10, 6, 7), dtype=float64, chunksize=(10, 1, 1)>\n",
      "Describe the DataArray:\n",
      " <xarray.DataArray 'array-1fa3948926acce3f8440e8a243559446' (tt: 10, xx: 6, yy: 7)>\n",
      "dask.array<shape=(10, 6, 7), dtype=float64, chunksize=(10, 1, 1)>\n",
      "Coordinates:\n",
      "  * tt       (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * xx       (xx) float64 0.0 2.0 4.0 6.0 8.0 10.0\n",
      "  * yy       (yy) float64 0.0 3.0 6.0 9.0 12.0 15.0 18.0 \n",
      "\n",
      "Regarde: The data do not print; they just indicate a dask array:\n",
      " dask.array<array, shape=(10, 6, 7), dtype=float64, chunksize=(10, 1, 1)> \n",
      "\n",
      "attributes: OrderedDict() \n",
      "\n",
      "coords: Coordinates:\n",
      "  * tt       (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * xx       (xx) float64 0.0 2.0 4.0 6.0 8.0 10.0\n",
      "  * yy       (yy) float64 0.0 3.0 6.0 9.0 12.0 15.0 18.0 \n",
      "\n",
      "dimensions: Frozen(SortedKeysDict({'tt': 10, 'xx': 6, 'yy': 7})) \n",
      "\n",
      "data_vars: Data variables:\n",
      "    speedfield  (tt, xx, yy) float64 dask.array<shape=(10, 6, 7), chunksize=(10, 1, 1)> \n",
      "\n",
      "No append method in the data_vars:\n",
      " ['get', 'items', 'keys', 'values', 'variables'] \n",
      "\n",
      "speedfield\n",
      "\n",
      "\n",
      "<class 'xarray.core.dataarray.DataArray'>\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell follows Scott Henderson's example to create a bunch of linear trends in time\n",
    "#   across a 2D spatial grid, roughed up with a bit of noise.\n",
    "\n",
    "nt = 10                                # Ten elements in the time dimension\n",
    "nx = 6                                 #     Six in the x\n",
    "ny = 7                                 #     Seven in the y\n",
    "\n",
    "images = np.ones([ny,nx,nt])           # A 3D numpy array of ones: Fast index is time (10), slow is y (7)\n",
    "values = np.arange(nt)                 # A list[] of floats 0., 1., ..., 9.\n",
    "noise = np.random.random([ny,nx,nt])   # A 3D numpy array of uniform random values on [0., 1.]\n",
    "                                       #   which would be indexed via [a, b, c]; not [a][b][c]\n",
    "\n",
    "cubeStart = (images*values)            # A 3D numpy array where the fast index (time) goes 0, 1, ..., 9\n",
    "                                       #   This uses 'broadcast multiplication' element-by-element along\n",
    "                                       #   the fast (right-most) index. What if values[] has length nx or ny? \n",
    "                                       #   Answer: This is no good, won't work. The broadcast list must match \n",
    "                                       #   the fast index in length.\n",
    "cubeNext = cubeStart + noise           # Element-by-element addition of the [0, 1] noise tensor\n",
    "cube = cubeNext.T                      # .T is Transpose: Now the fast index is time, then follows x, then y\n",
    "# print(cubeStart)\n",
    "\n",
    "# hold cube2 in reserve for later: The idea of adding a new DataArray to an existing Dataset\n",
    "cube2 = ((images*values) + noise + noise + noise).T\n",
    "\n",
    "# import dask is necessary to work with dask.array objects \n",
    "tlist = np.arange(nt)\n",
    "xlist = np.arange(0., nx*2., 2.)\n",
    "ylist = np.arange(0., ny*3., 3.)\n",
    "daska = dask.array.from_array(cube, chunks=(nt, 1, 1))\n",
    "print(daska[7,4,2])\n",
    "print(daska)\n",
    "\n",
    "da = xr.DataArray(daska,\n",
    "                  dims=('tt', 'xx', 'yy'),\n",
    "                  coords={'tt': tlist, 'xx': xlist, 'yy': ylist})\n",
    "\n",
    "print('Describe the DataArray:\\n', da, '\\n')\n",
    "print('Regarde: The data do not print; they just indicate a dask array:\\n', da.data, '\\n')\n",
    "\n",
    "dads=da.to_dataset(name='speedfield')\n",
    "\n",
    "# dir(dads)          # this gives a long listing that includes attrs, dims, coords, data_vars as elements of.\n",
    "                     #   We see these listed prominently when we print the Dataset. \n",
    "print('attributes:', dads.attrs, '\\n')\n",
    "print('coords:', dads.coords, '\\n')\n",
    "print('dimensions:', dads.dims, '\\n')\n",
    "print('data_vars:', dads.data_vars, '\\n')\n",
    "print('No append method in the data_vars:\\n', g.dirnou(dads.data_vars), '\\n')\n",
    "\n",
    "for dv in dads.data_vars: print(dv)\n",
    "print('\\n')\n",
    "\n",
    "# print(type(dads.attrs))\n",
    "# print(type(dads.coords))\n",
    "# print(type(dads.dims))\n",
    "# print(type(dads.data_vars))\n",
    "\n",
    "print(type(dads.tt))\n",
    "print(dads.tt.data)\n",
    "print('\\n')\n",
    "\n",
    "# To see the vast composition of a Dataset (state attributes and methods) use 'print(dir(dads))'.\n",
    "# The next cell elaborates all of this content for the dads Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tt coordinate data type is: <class 'numpy.ndarray'>\n",
      "the tt coordinate data describes itself: [0 1 2 3 4 5 6 7 8 9]\n",
      "the tt coordinate self-identifies as: <xarray.DataArray 'tt' (tt: 10)>\n",
      "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Coordinates:\n",
      "  * tt       (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "type of the tt coordinate is: <class 'xarray.core.dataarray.DataArray'>\n",
      "converting the coordinate data to a list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "dads Dataset: <xarray.Dataset>\n",
      "Dimensions:     (tt: 10, xx: 6, yy: 7)\n",
      "Coordinates:\n",
      "  * tt          (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * xx          (xx) float64 0.0 2.0 4.0 6.0 8.0 10.0\n",
      "  * yy          (yy) float64 0.0 3.0 6.0 9.0 12.0 15.0 18.0\n",
      "Data variables:\n",
      "    speedfield  (tt, xx, yy) float64 dask.array<shape=(10, 6, 7), chunksize=(10, 1, 1)> \n",
      "\n",
      "dads.speedfield has type: <class 'xarray.core.dataarray.DataArray'> \n",
      "\n",
      "speedfield with indices 1, 2, 3 (tt, xx, yy) is a DataArray:\n",
      " <xarray.DataArray 'speedfield' ()>\n",
      "dask.array<shape=(), dtype=float64, chunksize=()>\n",
      "Coordinates:\n",
      "    tt       int64 1\n",
      "    xx       float64 4.0\n",
      "    yy       float64 9.0 \n",
      "\n",
      "speedfield data value at same:\n",
      " 1.642824274460157 \n",
      "\n",
      "(speedfield with indices 10, 2, 3 (tt, xx, yy) fails with dimension 0 out of bounds)\n",
      "\n",
      "1.960462029769114\n",
      "1.5607363314531424\n",
      "1.642824274460157\n",
      "1.5159296413307188\n",
      "1.3511651027931313\n",
      "1.9581018960808396\n",
      "[0.1295798143860264, 1.642824274460157, 2.359036613796678, 3.7241057402743842, 4.3972553670051155, 5.434152142885317, 6.901777339469943, 7.9871844917501065, 8.189487203399684, 9.08100305524928]\n",
      "[1.960462029769114, 1.5607363314531424, 1.642824274460157, 1.5159296413307188, 1.3511651027931313, 1.9581018960808396]\n",
      "[1.6442198942444746, 1.6769186051905427, 1.9622083861803237, 1.642824274460157, 1.4048161675076154, 1.1064389712248355, 1.2537921589186067]\n",
      "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.00000000e+00, 1.62526165e-15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In top down order: \n",
    "#   We have a 'data array data set' dads: DataSet(One DataArray named 'speedfield')\n",
    "#     This has a 'tt' dimension and an associated 'tt' coordinate. \n",
    "#     The 'tt' coordinate is a DataArray with 10 int64 values\n",
    "#     Using the .data extension to this the coordinate gives an np.ndarray.\n",
    "#     This prints as a space-delimited array (not a comma-delimited list)\n",
    "#     At need it could be converted to a list using .tolist()\n",
    "# \n",
    "print('the tt coordinate data type is:', type(dads.tt.data))\n",
    "print('the tt coordinate data describes itself:', dads.tt.data)\n",
    "print('the tt coordinate self-identifies as:', dads.tt)\n",
    "print('type of the tt coordinate is:', type(dads.tt))\n",
    "print('converting the coordinate data to a list:', dads.tt.data.tolist())\n",
    "\n",
    "# The dads Dataset itself has just the one Data variable 'speedfield'.\n",
    "#   This is also a DataArray; indexed by three dimensional indices\n",
    "#   \n",
    "print('dads Dataset:', dads, '\\n')\n",
    "print('dads.speedfield has type:', type(dads.speedfield), '\\n')\n",
    "print('speedfield with indices 1, 2, 3 (tt, xx, yy) is a DataArray:\\n', dads.speedfield[1,2,3],'\\n')\n",
    "print('speedfield data value at same:\\n', float(dads.speedfield[1,2,3]),'\\n')\n",
    "print('(speedfield with indices 10, 2, 3 (tt, xx, yy) fails with dimension 0 out of bounds)\\n')\n",
    "\n",
    "for a in dads.speedfield[1,:,3]: print(float(a))\n",
    "\n",
    "print([float(a) for a in dads.speedfield[:,2,3]])\n",
    "print([float(a) for a in dads.speedfield[1,:,3]])\n",
    "print([float(a) for a in dads.speedfield[1,2,:]])\n",
    "# print('speedfield along the x axis:\\n', float(dads.speedfield[1,:,3]))\n",
    "\n",
    "y=np.arange(0.,30.,3); print(y)\n",
    "np.polyfit(dads.tt.data, y, 1)\n",
    "\n",
    "# dads1 = xr.Dataset({'tempo': (['x', 'y', 'time'],  temp),\n",
    "#    ....:                  'precipitation': (['x', 'y', 'time'], precip)},\n",
    "#    ....:                 coords={'lon': (['x', 'y'], lon),\n",
    "#    ....:                         'lat': (['x', 'y'], lat),\n",
    "#    ....:                         'time': pd.date_range('2014-09-06', periods=3),\n",
    "#    ....:                         'reference_time': pd.Timestamp('2014-09-05')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'fred' (waviness: 7)>\n",
      "array([ 0. ,  2.1,  3.9,  nan,  nan, 10. , 12.1])\n",
      "Coordinates:\n",
      "  * waviness  (waviness) int64 0 1 2 3 4 5 6\n",
      "<xarray.DataArray 'fred' (waviness: 5)>\n",
      "array([ 0. ,  2.1,  3.9, 10. , 12.1])\n",
      "Coordinates:\n",
      "  * waviness  (waviness) int64 0 1 2 5 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0082089552238807"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relocate\n",
    "# shows a use of .dropna() under simple circumstances\n",
    "\n",
    "x=xr.DataArray([0., 2.1, 3.9, np.nan, np.nan, 10., 12.1], name='fred', coords=[('waviness', range(7))])\n",
    "print(x)\n",
    "\n",
    "y=x.dropna('waviness')\n",
    "print(y)\n",
    "\n",
    "fit = np.polyfit(x.dropna('waviness').waviness, x.dropna('waviness').data, 1); fit[0]  # slope of about 2.0\n",
    "\n",
    "# fit1 = np.polyfit(x.waviness, x.data, 1); fit1[0]        # produces a nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# golive3 LS learning path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b52caeb890d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# determine the lat/lon bounding box of the aggregated region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mxHi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0myHi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mn0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vv' is not defined"
     ]
    }
   ],
   "source": [
    "# relocate this to a coordinate section\n",
    "\n",
    "# Determining how many elements in a 1-D dimension: Dataset uses 'dims' and DataArray uses 'sizes'\n",
    "# vv.to_dataset().dims['x']\n",
    "# vv.sizes['x']\n",
    "\n",
    "# determine the lat/lon bounding box of the aggregated region\n",
    "xHi = vv.sizes['x'] - 1\n",
    "yHi = vv.sizes['y'] - 1\n",
    "n0 = vv.y[0].data\n",
    "n1 = vv.y[yHi].data\n",
    "e0 = vv.x[0].data\n",
    "e1 = vv.x[xHi].data\n",
    "print(e0, e1, n0, n1, '\\n')\n",
    "print('corner geographical coordinates:')\n",
    "print(utm.to_latlon(e0, n0, 7, 'V'))\n",
    "print(utm.to_latlon(e1, n0, 7, 'V'))\n",
    "print(utm.to_latlon(e0, n1, 7, 'V'))\n",
    "print(utm.to_latlon(e1, n1, 7, 'V'))\n",
    "print('\\n')\n",
    "print('latitude band approx', '%.1f' % (2.6*111.), 'km')\n",
    "\n",
    "# moves vv back to Dataset status 'vvds' but renames the Data variable 'vv'\n",
    "# vvds=vv.to_dataset(name='vv')\n",
    "# print(vvds)                        # time, x, y dimensions and the Data variable 'vv'\n",
    "# vvds['vv'].values          # prints a bunch of edge nans; and ellipses... not interesting\n",
    "# print(vvds.vv.sel(y=6710000.,x=500000.,method='nearest').data)    # ...is 75 values, mostly nan\n",
    "\n",
    "# relocate this to a time section\n",
    "# This converts datetime64 to epoch-relative times (floats)\n",
    "# See also Joe's inline conversion example that uses .astype() on Stack Overflow\n",
    "#   This has been commented out in the practice code for solving the LS implementation\n",
    "#   on the 'cube' array\n",
    "if False:\n",
    "    # I would like a time axis that has decimal time in some familiar unit like 1 day. Why? \n",
    "    #   Because when I try to fit a line to the data it complains...\n",
    "    # Since our time range is 2013 to 2018 we will have values of a couple thousand days; \n",
    "    #   but that is pretty reasonable particularly when our data for speed are in meters per day.\n",
    "    # The first step is to choose some epoch; I used January 1 2013 as prior to all the GOLIVE data.\n",
    "    # With this epoch in hand we convert from datetime.datetime to np.datetime64.\n",
    "    # We then reference a datetime in the vvds Dataset, subtract the epoch and convert to (24-hour) units\n",
    "    dtEpoch = datetime(2013,1,1,0,0,0)\n",
    "    dt64Epoch = np.datetime64(datetime(2013,1,1,0,0,0))\n",
    "    ts = (vvds.time[0].data - dt64Epoch) / np.timedelta64(24, 'h')\n",
    "    print(ts, 'days from Jan 1 2013 to the first timestamp of the Dataset:', vvds.time[0].data)\n",
    "\n",
    "    # This next bit converts the vvds datetime64 version of time to epoch time in decimal days\n",
    "    #   ...but since this is done above it will throw an error now\n",
    "    def ETimeDDays(timeX): return (timeX - dt64(datetime(2013,1,1))) / td64(24, 'h')\n",
    "    vvds['time'] = ('time', [ETimeDDays(atime.data) for atime in vvds.time])\n",
    "\n",
    "# vvds.coords          # where time is datetime64; with hours added to avoid collisions\n",
    "# vvds.dims            # 75 source results x (spatial extent)\n",
    "# print(vvds)          # the Dataset overview; but now time will be a float\n",
    "# vvds.count()         # produces like 10,000,000 which is perhaps the non-nan count?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "There are two types of `coordinates` in `xarray`: Dimension coordinates (1D, correspond precisely by name to \n",
    "their `dimension`, marked by an asterisk (\\*) as above; and non-dimension coordinates. These latter contain\n",
    "coordinate data but are not a dimension coordinate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relocate\n",
    "# This cell operated on a Datasetwith the idea of isolating a single location \n",
    "# The learning idea would support 'I have a vast array; what is the time series at some point of interest'\n",
    "# What is needed is 'how to choose that point of interest'\n",
    "\n",
    "# %%time\n",
    "# \n",
    "# vvds.assign_coords(dtime=EpochTimeDecimalDays(vvds.time))\n",
    "# vvds.dtime=vvds.time.\n",
    "# print(dir(vvds.time[0].data))\n",
    "# print(vvds.time[0].data)\n",
    "# print(type(vvds.time[0].data))\n",
    "# dir(vvds.time)\n",
    "# \n",
    "# dsRob = vvds.chunk(chunks={'time':-1, 'y':400, 'x':400})\n",
    "# print(dsRob, '\\n')\n",
    "# timeseries = dsRob.vv\n",
    "# apoint = timeseries.sel(y=6710000.,x=500000.,method='nearest')\n",
    "# print(apoint.data)            \n",
    "# print(vvds.vv.sel(y=6710000.,x=500000.,method='nearest').data)     # prints 75 values, mostly nan\n",
    "# timeseries.plot()\n",
    "# print(dsRob.speedfield.sel(y=6710000.,x=500000.,method='nearest').data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9e77173d664e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This works with a single location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6728488.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m517888.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlsvel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlstime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vv' is not defined"
     ]
    }
   ],
   "source": [
    "# Relocate\n",
    "# This continues the theme of the prior cell; but starting over\n",
    "# At a single location: \n",
    "#   - selects out a velocity vector with a time axis\n",
    "#   - creates empty lists lsx and lsy, sets up a time coordinate list lstime\n",
    "#   - using a loop populates lsx[] and lsy[] with only non-nan values\n",
    "#   - applies a median filter to the speed data\n",
    "#   - plots four things\n",
    "#     - the unfiltered data\n",
    "#     - the median filter data\n",
    "#     - the fit to unfiltered\n",
    "#     - the fit to filtered\n",
    "# This works with a single location\n",
    "y, x = 6728488.,517888.\n",
    "lsvel = vv.sel(y=y,x=x,method='nearest').data\n",
    "lstime, lsx, lsy = vv['time'], [], []\n",
    "for d in range(len(lsvel)):\n",
    "    if not np.isnan(lsvel[d]): \n",
    "        lsx.append(float(lstime[d].data))\n",
    "        lsy.append(lsvel[d])\n",
    "lsymf = mf(lsy, kernel_size=3); \n",
    "fig,axes = plt.subplots(1); fig.set_size_inches(6,4)\n",
    "axes.set(xlabel='time (days)', ylabel = 'm / d', title='signal (black) and median filter (red)')\n",
    "axes.plot(lsx, lsy, color='black'); axes.plot(lsx, lsymf, color='red')\n",
    "fit = np.polyfit(lsx, lsymf, 1); fitx=[lsx[0],lsx[-1]]; fity=[fit[1] + fit[0]*fitx[0],fit[1] + fit[0]*fitx[1]]\n",
    "axes.plot(fitx, fity, color='blue')\n",
    "fit0 = np.polyfit(lsx, lsy, 1); fitx0=[lsx[0],lsx[-1]]; fity0=[fit0[1] + fit0[0]*fitx0[0],fit0[1] + fit0[0]*fitx0[1]]\n",
    "axes.plot(fitx0, fity0, color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with nan missing values in a LS fit\n",
    "\n",
    "- xarray.DataArray is a labeled, multi-dimensional array\n",
    "  - DataArray contents\n",
    "    - values: a numpy.ndarray holding the array’s values (in an xr.Dataset these are Data variables)\n",
    "    - dims: dimension names for each axis (e.g., ('x', 'y', 'z'))\n",
    "    - coords: a dict-like container of arrays (coordinates) that label each point \n",
    "      - e.g. 1-dimensional arrays of numbers, datetime objects or strings\n",
    "    - attrs: an OrderedDict to hold arbitrary metadata (attributes)\n",
    "    - name: optional string; the name for the data\n",
    "  - Creating a DataArray\n",
    "    - The DataArray constructor takes:\n",
    "      - data: a multi-dimensional array of values (e.g., a numpy ndarray, Series, DataFrame or Panel)\n",
    "      - coords: a list or dictionary of coordinates. \n",
    "        - If a list, it should be a list of tuples where \n",
    "          - the first element is the dimension name and \n",
    "          - the second element is the corresponding coordinate array_like object\n",
    "      - dims: a list of dimension names. If omitted and coords is a list of tuples, dimension names are taken from coords.\n",
    "      - attrs: a dictionary of attributes to add to the instance\n",
    "      - name: a string that names the instance\n",
    "\n",
    "- dropna(dim, how='any', thresh=None)\n",
    "  - Returns a new DataArray with dropped labels for missing values along the provided dimension.\n",
    "  - dim is a string; the name of the dimension along which to drop missing values. \n",
    "    - Dropping along multiple dimensions simultaneously is not yet supported\n",
    "    - how:{‘any’, ‘all’}, optional\n",
    "      - any : if any NA values are present, drop that label\n",
    "      - all : if all values are NA, drop that label\n",
    "     - thresh:int, default None; if supplied, require this many non-NA values\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xarray.core.dataarray.DataArray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7ff39fd1a278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's do a 2D array with a 3rd time axis and go for fits in that axis \n",
    "nt = 10                                # Ten elements in the time dimension\n",
    "nx = 6                                 #     Six in the x\n",
    "ny = 7                                 #     Seven in the y\n",
    "images = np.ones([ny,nx,nt])           # A 3D numpy array of ones: Fast index is time (10), slow is y (7)\n",
    "values = np.arange(0., nt*2., 2.)      # A list[] of floats 0., 2., ..., 18.\n",
    "# print(values) gives us 0., 2., ..., 18.\n",
    "\n",
    "noise = np.random.random([ny,nx,nt])   # A 3D numpy array of uniform random values on [0., 1.]\n",
    "                                       #   which would be indexed via [a, b, c]; not [a][b][c]\n",
    "# print(noise)\n",
    "\n",
    "cubeStart = images*values              # A 3D numpy array where the fast index (time) goes 0, 1, ..., 9\n",
    "                                       #   This uses 'broadcast multiplication' element-by-element along\n",
    "                                       #   the fast (right-most) index. What if values[] has length nx or ny? \n",
    "                                       #   Answer: This is no good, won't work. The broadcast list must match \n",
    "                                       #   the fast index in length.\n",
    "cubeNext = cubeStart + noise           # Element-by-element addition of the [0, 1] noise tensor\n",
    "cube = cubeNext.T                      # .T is Transpose: Now the fast index is time, then follows x, then y\n",
    "\n",
    "# print(cube.shape) gives (10,6,7)\n",
    "\n",
    "nNans = 6*7*7\n",
    "for i in range(nNans):\n",
    "    i1 = ri(0, 9)\n",
    "    i2 = ri(0, 5)\n",
    "    i3 = ri(0, 6)\n",
    "    cube[i1, i2, i3] = np.nan\n",
    "\n",
    "# counter = np.zeros([6, 7])\n",
    "# for i in range(7):\n",
    "#     for j in range(6):\n",
    "#         c = 0.\n",
    "#         for k in range(10):\n",
    "#             # print(cube[k,j,i]) prints values or occasional nans\n",
    "#             if np.isnan(cube[k,j,i]): c += 1.\n",
    "#         counter[j, i] = c\n",
    "# print(counter)\n",
    "\n",
    "dacube = xr.DataArray(cube, name='cubedata', coords=[('time', range(10)),('x',range(6)),('y',range(7))])\n",
    "\n",
    "def _calc_slope(x, y):\n",
    "    '''wrapper that returns the slop from a linear regression fit of x and y'''\n",
    "    # return stats.linregress(x, y)[0]  # extract slope only\n",
    "    # print(len(x), '     ', x, '    ', y)\n",
    "    # print(x, y)\n",
    "    idx = np.isfinite(y)\n",
    "    # nFalse = np.size(idx) - np.count_nonzero(idx)\n",
    "    if np.count_nonzero(idx) < 4: return 0.\n",
    "    y_medianfilter = mf(y[idx], kernel_size=3); \n",
    "    return np.polyfit(x[idx], y_medianfilter, 1)[0]\n",
    "\n",
    "def linear_trend(obj):\n",
    "    # time_nums = xr.DataArray(obj['time'].values.astype(np.float),\n",
    "    #                          dims='time',\n",
    "    #                          coords={'time': obj['time']},\n",
    "    #                          name='time_nums')\n",
    "    trend = xr.apply_ufunc(_calc_slope, obj.time, obj,\n",
    "                           vectorize=True,\n",
    "                           input_core_dims=[['time'], ['time']],\n",
    "                           output_core_dims=[[]],\n",
    "                           output_dtypes=[np.float],\n",
    "                           dask='parallelized')\n",
    "    return trend\n",
    "\n",
    "# lt = linear_trend(dacube.dropna('time'))\n",
    "lt = linear_trend(dacube)\n",
    "print(type(lt))\n",
    "lt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Line plot methods or kwargs...\n",
    "\n",
    "- axes\n",
    "- draw\n",
    "- figure\n",
    "- lineStyles\n",
    "- markers\n",
    "- set_alpha\n",
    "- set_color\n",
    "- set_data\n",
    "- set_drawstyle\n",
    "- set_label\n",
    "- set_ls\n",
    "- set_lw\n",
    "- set_marker\n",
    "- set_markeredgecolor\n",
    "- set_markeredgewidth\n",
    "- set_markerfacecolor\n",
    "- set_markersize\n",
    "- set_visible\n",
    "- set_xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
