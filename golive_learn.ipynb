{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utm in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pygeotools in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: gdal in /opt/conda/lib/python3.6/site-packages (from pygeotools)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->pygeotools)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->pygeotools)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->pygeotools)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "!pip install utm\n",
    "!pip install pygeotools\n",
    "\n",
    "import timeit\n",
    "from datetime import timedelta, datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.signal import medfilt as mf\n",
    "from random import randint as ri\n",
    "\n",
    "from ipywidgets import *                # interactivity\n",
    "from traitlets import dlink             # interactivity\n",
    "import sys\n",
    "import os\n",
    "import utm\n",
    "\n",
    "# from osgeo import gdal \n",
    "# from pygeotools.lib import iolib,timelib\n",
    "\n",
    "import golive_utility as g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helen's Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset('sample.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (SnowIce_profiles: 3, SnowLiq_profiles: 3, SnowTProf_profiles: 3, SoilMoist_profiles: 4, SoilTemp_profiles: 4, east_west: 137, north_south: 81, time: 1, z_snow_profiles: 3, z_soil_profiles: 4)\n",
       "Coordinates:\n",
       "  * time              (time) datetime64[ns] 2003-02-01\n",
       "Dimensions without coordinates: SnowIce_profiles, SnowLiq_profiles, SnowTProf_profiles, SoilMoist_profiles, SoilTemp_profiles, east_west, north_south, z_snow_profiles, z_soil_profiles\n",
       "Data variables:\n",
       "    lat               (north_south, east_west) float32 ...\n",
       "    lon               (north_south, east_west) float32 ...\n",
       "    Swnet_tavg        (north_south, east_west) float32 ...\n",
       "    Lwnet_tavg        (north_south, east_west) float32 ...\n",
       "    Qle_tavg          (north_south, east_west) float32 ...\n",
       "    Qh_tavg           (north_south, east_west) float32 ...\n",
       "    Qg_tavg           (north_south, east_west) float32 ...\n",
       "    Snowf_tavg        (north_south, east_west) float32 ...\n",
       "    Rainf_tavg        (north_south, east_west) float32 ...\n",
       "    Evap_tavg         (north_south, east_west) float32 ...\n",
       "    Qs_tavg           (north_south, east_west) float32 ...\n",
       "    Qsb_tavg          (north_south, east_west) float32 ...\n",
       "    Qsm_tavg          (north_south, east_west) float32 ...\n",
       "    VegT_tavg         (north_south, east_west) float32 ...\n",
       "    AvgSurfT_tavg     (north_south, east_west) float32 ...\n",
       "    RadT_tavg         (north_south, east_west) float32 ...\n",
       "    Albedo_tavg       (north_south, east_west) float32 ...\n",
       "    SWE_tavg          (north_south, east_west) float32 ...\n",
       "    SnowDepth_tavg    (north_south, east_west) float32 ...\n",
       "    SnowIce_inst      (SnowIce_profiles, north_south, east_west) float32 ...\n",
       "    SnowAge_tavg      (north_south, east_west) float32 ...\n",
       "    SoilMoist_tavg    (SoilMoist_profiles, north_south, east_west) float32 ...\n",
       "    SoilTemp_tavg     (SoilTemp_profiles, north_south, east_west) float32 ...\n",
       "    ECanop_tavg       (north_south, east_west) float32 ...\n",
       "    TVeg_tavg         (north_south, east_west) float32 ...\n",
       "    ESoil_tavg        (north_south, east_west) float32 ...\n",
       "    CanopInt_tavg     (north_south, east_west) float32 ...\n",
       "    SubSnow_tavg      (north_south, east_west) float32 ...\n",
       "    TWS_tavg          (north_south, east_west) float32 ...\n",
       "    GWS_tavg          (north_south, east_west) float32 ...\n",
       "    Snowcover_tavg    (north_south, east_west) float32 ...\n",
       "    SnowTProf_inst    (SnowTProf_profiles, north_south, east_west) float32 ...\n",
       "    Wind_f_tavg       (north_south, east_west) float32 ...\n",
       "    Rainf_f_tavg      (north_south, east_west) float32 ...\n",
       "    Tair_f_tavg       (north_south, east_west) float32 ...\n",
       "    Qair_f_tavg       (north_south, east_west) float32 ...\n",
       "    Psurf_f_tavg      (north_south, east_west) float32 ...\n",
       "    SWdown_f_tavg     (north_south, east_west) float32 ...\n",
       "    LWdown_f_tavg     (north_south, east_west) float32 ...\n",
       "    LAI_tavg          (north_south, east_west) float32 ...\n",
       "    TotalPrecip_tavg  (north_south, east_west) float32 ...\n",
       "    ActSnowNL_inst    (north_south, east_west) float32 ...\n",
       "    z_snow_inst       (z_snow_profiles, north_south, east_west) float32 ...\n",
       "    z_soil_inst       (z_soil_profiles, north_south, east_west) float32 ...\n",
       "    SnowLiq_inst      (SnowLiq_profiles, north_south, east_west) float32 ...\n",
       "Attributes:\n",
       "    missing_value:           -9999.0\n",
       "    NUM_SOIL_LAYERS:         4\n",
       "    SOIL_LAYER_THICKNESSES:  [0.1 0.3 0.6 1. ]\n",
       "    title:                   LIS land surface model output\n",
       "    institution:             NASA GSFC\n",
       "    source:                  \n",
       "    history:                 created on date: 2018-12-07T18:48:14.415\n",
       "    references:              Kumar_etal_EMS_2006, Peters-Lidard_etal_ISSE_2007\n",
       "    conventions:             CF-1.6\n",
       "    comment:                 website: http://lis.gsfc.nasa.gov/\n",
       "    MAP_PROJECTION:          EQUIDISTANT CYLINDRICAL\n",
       "    SOUTH_WEST_CORNER_LAT:   20.875\n",
       "    SOUTH_WEST_CORNER_LON:   66.875\n",
       "    DX:                      0.25\n",
       "    DY:                      0.25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:           (SnowIce_profiles: 3, SnowLiq_profiles: 3, SnowTProf_profiles: 3, SoilMoist_profiles: 4, SoilTemp_profiles: 4, east_west: 137, north_south: 81, time: 1, z_snow_profiles: 3, z_soil_profiles: 4)\n",
       "Coordinates:\n",
       "    lat               (north_south, east_west) float32 ...\n",
       "    lon               (north_south, east_west) float32 ...\n",
       "  * time              (time) datetime64[ns] 2003-02-01\n",
       "Dimensions without coordinates: SnowIce_profiles, SnowLiq_profiles, SnowTProf_profiles, SoilMoist_profiles, SoilTemp_profiles, east_west, north_south, z_snow_profiles, z_soil_profiles\n",
       "Data variables:\n",
       "    Swnet_tavg        (north_south, east_west) float32 ...\n",
       "    Lwnet_tavg        (north_south, east_west) float32 ...\n",
       "    Qle_tavg          (north_south, east_west) float32 ...\n",
       "    Qh_tavg           (north_south, east_west) float32 ...\n",
       "    Qg_tavg           (north_south, east_west) float32 ...\n",
       "    Snowf_tavg        (north_south, east_west) float32 ...\n",
       "    Rainf_tavg        (north_south, east_west) float32 ...\n",
       "    Evap_tavg         (north_south, east_west) float32 ...\n",
       "    Qs_tavg           (north_south, east_west) float32 ...\n",
       "    Qsb_tavg          (north_south, east_west) float32 ...\n",
       "    Qsm_tavg          (north_south, east_west) float32 ...\n",
       "    VegT_tavg         (north_south, east_west) float32 ...\n",
       "    AvgSurfT_tavg     (north_south, east_west) float32 ...\n",
       "    RadT_tavg         (north_south, east_west) float32 ...\n",
       "    Albedo_tavg       (north_south, east_west) float32 ...\n",
       "    SWE_tavg          (north_south, east_west) float32 ...\n",
       "    SnowDepth_tavg    (north_south, east_west) float32 ...\n",
       "    SnowIce_inst      (SnowIce_profiles, north_south, east_west) float32 ...\n",
       "    SnowAge_tavg      (north_south, east_west) float32 ...\n",
       "    SoilMoist_tavg    (SoilMoist_profiles, north_south, east_west) float32 ...\n",
       "    SoilTemp_tavg     (SoilTemp_profiles, north_south, east_west) float32 ...\n",
       "    ECanop_tavg       (north_south, east_west) float32 ...\n",
       "    TVeg_tavg         (north_south, east_west) float32 ...\n",
       "    ESoil_tavg        (north_south, east_west) float32 ...\n",
       "    CanopInt_tavg     (north_south, east_west) float32 ...\n",
       "    SubSnow_tavg      (north_south, east_west) float32 ...\n",
       "    TWS_tavg          (north_south, east_west) float32 ...\n",
       "    GWS_tavg          (north_south, east_west) float32 ...\n",
       "    Snowcover_tavg    (north_south, east_west) float32 ...\n",
       "    SnowTProf_inst    (SnowTProf_profiles, north_south, east_west) float32 ...\n",
       "    Wind_f_tavg       (north_south, east_west) float32 ...\n",
       "    Rainf_f_tavg      (north_south, east_west) float32 ...\n",
       "    Tair_f_tavg       (north_south, east_west) float32 ...\n",
       "    Qair_f_tavg       (north_south, east_west) float32 ...\n",
       "    Psurf_f_tavg      (north_south, east_west) float32 ...\n",
       "    SWdown_f_tavg     (north_south, east_west) float32 ...\n",
       "    LWdown_f_tavg     (north_south, east_west) float32 ...\n",
       "    LAI_tavg          (north_south, east_west) float32 ...\n",
       "    TotalPrecip_tavg  (north_south, east_west) float32 ...\n",
       "    ActSnowNL_inst    (north_south, east_west) float32 ...\n",
       "    z_snow_inst       (z_snow_profiles, north_south, east_west) float32 ...\n",
       "    z_soil_inst       (z_soil_profiles, north_south, east_west) float32 ...\n",
       "    SnowLiq_inst      (SnowLiq_profiles, north_south, east_west) float32 ...\n",
       "Attributes:\n",
       "    missing_value:           -9999.0\n",
       "    NUM_SOIL_LAYERS:         4\n",
       "    SOIL_LAYER_THICKNESSES:  [0.1 0.3 0.6 1. ]\n",
       "    title:                   LIS land surface model output\n",
       "    institution:             NASA GSFC\n",
       "    source:                  \n",
       "    history:                 created on date: 2018-12-07T18:48:14.415\n",
       "    references:              Kumar_etal_EMS_2006, Peters-Lidard_etal_ISSE_2007\n",
       "    conventions:             CF-1.6\n",
       "    comment:                 website: http://lis.gsfc.nasa.gov/\n",
       "    MAP_PROJECTION:          EQUIDISTANT CYLINDRICAL\n",
       "    SOUTH_WEST_CORNER_LAT:   20.875\n",
       "    SOUTH_WEST_CORNER_LON:   66.875\n",
       "    DX:                      0.25\n",
       "    DY:                      0.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.set_coords(['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f5f5b801dd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.lon.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:              (space: 3)\n",
      "Coordinates:\n",
      "  * space                (space) <U2 'IA' 'IL' 'IN'\n",
      "Data variables:\n",
      "    2000-01-01 00:00:00  (space) float64 0.7967 0.8937 0.5406\n",
      "    2000-01-02 00:00:00  (space) float64 0.5157 0.001738 0.7441\n",
      "    2000-01-03 00:00:00  (space) float64 0.2037 0.918 0.4862\n",
      "    2000-01-04 00:00:00  (space) float64 0.08153 0.3453 0.7992\n",
      "Attributes:\n",
      "    Here:        We\n",
      "    Include:     Metatada\n",
      "    Attributes:  As a dictionary\n",
      "    throw in:    some meters \n",
      "\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (space: 3, time: 4)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 2000-01-04\n",
      "  * space    (space) <U2 'IA' 'IL' 'IN'\n",
      "Data variables:\n",
      "    yawlp    (time, space) float64 0.7967 0.8937 0.5406 ... 0.3453 0.7992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (dope: 4, latitude: 24, longitude: 18, moped: 5, q: 1, space: 3, time: 4)\n",
       "Coordinates:\n",
       "  * space                (space) <U2 'IA' 'IL' 'IN'\n",
       "    lat                  (latitude) float64 0.0 1.0 2.0 3.0 ... 21.0 22.0 23.0\n",
       "    lon                  (longitude) float64 0.0 1.0 2.0 3.0 ... 15.0 16.0 17.0\n",
       "  * q                    (q) float64 1.4\n",
       "    q2                   float64 1.5\n",
       "  * moped                (moped) int64 0 1 2 3 4\n",
       "    reference_time       datetime64[ns] 2014-09-05\n",
       "  * dope                 (dope) datetime64[ns] 2000-01-01 ... 2000-01-04\n",
       "Dimensions without coordinates: latitude, longitude, time\n",
       "Data variables:\n",
       "    2000-01-01 00:00:00  (space) float64 0.7967 0.8937 0.5406\n",
       "    2000-01-02 00:00:00  (space) float64 0.5157 0.001738 0.7441\n",
       "    2000-01-03 00:00:00  (space) float64 0.2037 0.918 0.4862\n",
       "    2000-01-04 00:00:00  (space) float64 0.08153 0.3453 0.7992\n",
       "    temp                 (time, space) float64 0.4643 0.02042 ... 0.6146 0.5932\n",
       "    precip               (space, time) float64 2.698 4.144 4.019 ... 3.966 4.872\n",
       "Attributes:\n",
       "    Here:         is change! But do not fail to\n",
       "    Include:      Metatada\n",
       "    Attributes:   As a dictionary\n",
       "    throw in:     some meters\n",
       "    throwing in:  another attribute"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from the documentation: A sequence of operations on a DataArray showing some finesse points\n",
    "#   - using numpy to generate random 2D array\n",
    "#   - a spatial coordinate can have labels that are string\n",
    "#   - pandas generates a date sequence with default day intervals\n",
    "#   - declaring a DataArray\n",
    "#     - providing data\n",
    "#     - providing coordinates\n",
    "#     - providing dimensions\n",
    "#     - providing a name\n",
    "#     - providing attributes\n",
    "#   - adding another attribute\n",
    "#   - changing the name: Producing a new DataArray; not in-place\n",
    "\n",
    "rdata = np.random.rand(4, 3)                        # a 2D ndarray of random values with dimensions as given\n",
    "locs = ['IA', 'IL', 'IN']                           # three state abbreviations\n",
    "times = pd.date_range('2000-01-01', periods=4)      # default period is 1 day \n",
    "foo = xr.DataArray(rdata, coords=[times, locs],     # first argument is always the data\n",
    "    dims=['time', 'space'], name='Amelia',          # This name Amelia associates with the data, not the DataArray object\n",
    "    attrs={'Here': 'We', 'Include': 'Metatada',\n",
    "          'Attributes': 'As a dictionary'})\n",
    "                   \n",
    "foo.attrs['throw in'] = 'some meters'\n",
    "\n",
    "foo = foo.rename('AmeliaB')                         # 'rename()' returns a new DataArray without modifying foo\n",
    "                                                    #   so we re-assign the new object to foo\n",
    "foo                                                 # notice that 'rdata' is not mentioned but AmeliaB is\n",
    "\n",
    "fubar=foo.to_dataset(dim='time')\n",
    "fubar1 = foo.to_dataset(name='yawlp')\n",
    "print(fubar, '\\n')                        # The DataArray is broken apart in the 'time' dimension to produce\n",
    "                                          #   a series of Data variables in the Dataset (using time coordinates)\n",
    "print(fubar1)                             # AmeliaB becomes yawlp\n",
    "\n",
    "# from the fubar dataset with two coordinates 'space' and 'time': We continue by adding both\n",
    "#   some Data variables and some Coordinates (which in some cases add dimensions).\n",
    "\n",
    "# Add two Data variables\n",
    "fubar['temp'] = (('time', 'space'), np.random.rand(4, 3))\n",
    "fubar['precip'] = (('space', 'time'), np.random.rand(3,4)*5.)\n",
    "\n",
    "######\n",
    "#\n",
    "# Now change gears: What follows applies to coords and dims; this is no longer Data variable territory\n",
    "#\n",
    "#####\n",
    "\n",
    "# Add two coordinates that will be non-dimensional\n",
    "fubar.coords['lat'] = ('latitude', np.arange(24.))               # implicitly declares dimension latitude\n",
    "fubar.coords['lon'] = ('longitude', np.arange(18.))              #   and longitude. Since these are not the\n",
    "                                                                 #   same as the coordinate names 'lat' and 'lon'\n",
    "                                                                 #   these coords are 'non-dimension coordinates'\n",
    "\n",
    "\n",
    "# As there are not coords matching dims 'latitude' and 'longitude' they become 'dimensions without coordinates'.\n",
    "# 'time' is another DWC as it was devalued when fubar was created with: fubar=foo.to_dataset(dim='time'). \n",
    "# Since this broke the AmeliaB data by time into multiple DataArrays there was no longer a time dimension.\n",
    "\n",
    "\n",
    "# Add a coordinate that is dimensional, having coordinate name = dimension name\n",
    "fubar.coords['q'] = (('q', [1.4]))\n",
    "fubar.coords['q2'] = 1.5                                         # single value does not imply and therefore \n",
    "                                                                 #   fails to create dimension 'q2'\n",
    "fubar.coords['moped'] = np.arange(5)                             # multiple values imply and create dimension 'moped'\n",
    "fubar.coords['reference_time'] = pd.Timestamp('2014-09-05')      # Single value: No dimension implied\n",
    "fubar.coords['dope'] = pd.date_range('2000-01-01', periods=4)    # Multiple values: Dimension of same name implied\n",
    "\n",
    "######\n",
    "#\n",
    "# Now change gears again: This is modification and addition to attrs\n",
    "#\n",
    "#####\n",
    "\n",
    "fubar.attrs['throwing in'] = 'another attribute'\n",
    "fubar.attrs['Here'] = 'is change! But do not fail to'\n",
    "\n",
    "fubar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- T no parens; Transpose by reversing order of dimensions\n",
    "\n",
    "- argmax\n",
    "- argmin\n",
    "- argsort\n",
    "- assign_attrs\n",
    "- assign_coords\n",
    "- astype\n",
    "- attrs\n",
    "- bfill\n",
    "- broadcast_equals\n",
    "- chunk\n",
    "- chunks\n",
    "- clip\n",
    "- close\n",
    "- combine_first\n",
    "- compute\n",
    "- conj\n",
    "- conjugate\n",
    "- coords\n",
    "- copy\n",
    "- count\n",
    "- cumprod\n",
    "- cumsum\n",
    "- data\n",
    "- diff\n",
    "- differentiate\n",
    "- dims\n",
    "- dot\n",
    "- drop\n",
    "\n",
    "\n",
    "### `dropna()` gets its own section \n",
    "\n",
    "\n",
    "- dropna() gets its own section\n",
    "\n",
    "\n",
    "### to continue...\n",
    "\n",
    "- dt\n",
    "- dtype\n",
    "- encoding\n",
    "- equals\n",
    "- expand_dims\n",
    "- ffill\n",
    "- fillna\n",
    "- from_cdms2\n",
    "- from_dict\n",
    "- from_iris\n",
    "- from_series\n",
    "- get_axis_num\n",
    "- get_index\n",
    "- groupby\n",
    "- groupby_bins\n",
    "- identical\n",
    "- imag\n",
    "- indexes\n",
    "- interp\n",
    "- interp_like\n",
    "- interpolate_na\n",
    "\n",
    "- isin\n",
    "- isnull\n",
    "- item\n",
    "- load\n",
    "- loc\n",
    "- max\n",
    "- mean\n",
    "- median\n",
    "- min\n",
    "- name\n",
    "- nbytes\n",
    "- ndim\n",
    "- notnull\n",
    "- persist\n",
    "- pipe\n",
    "- plot\n",
    "- prod\n",
    "- quantile\n",
    "- rank\n",
    "- real\n",
    "- reduce\n",
    "- reindex\n",
    "- reindex_like\n",
    "- rename\n",
    "- reorder_levels\n",
    "- resample\n",
    "- reset_coords\n",
    "- reset_index\n",
    "- roll\n",
    "- rolling\n",
    "- round\n",
    "- searchsorted\n",
    "\n",
    "- set_index\n",
    "- shape\n",
    "- shift\n",
    "- size\n",
    "- sizes\n",
    "- sortby\n",
    "- squeeze\n",
    "- stack\n",
    "- std\n",
    "- sum\n",
    "- swap_dims\n",
    "- to_cdms2\n",
    "- to_dataframe\n",
    "- to_dataset\n",
    "- to_dict\n",
    "- to_index\n",
    "- to_iris()\n",
    "- to_masked_array()\n",
    "- to_netcdf()\n",
    "- to_pandas()\n",
    "- to_series()\n",
    "- transpose()\n",
    "- unstack()\n",
    "- values()\n",
    "- var()\n",
    "- variable()\n",
    " \n",
    " #### Also found in Dataset\n",
    " \n",
    "- all()\n",
    "- any()\n",
    "- isel\n",
    "- isel_points()\n",
    "- sel\n",
    "- sel_points\n",
    "- where()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Continuing with `dads` attributes (methods and state variables)\n",
    "\n",
    "#### State attributes specific to this particular *`dads`* Dataset\n",
    "\n",
    "\n",
    "- `tt, xx, yy` are both coordinates and dimensions within `dads`. In this context they are *coordinates*, not *dimensions*.\n",
    "- `speedfield` is a Data variable within `dads`\n",
    "\n",
    "`'tt' in dads and 'speedfield' in dads # prints True`\n",
    "\n",
    "#### Modify Dataset structure\n",
    "\n",
    "- set_coords(string or list of strings)             migrates named Data variable(s) into Coordinates\n",
    "\n",
    "\n",
    "#### Selection and comparison methods\n",
    "\n",
    "\n",
    "- where()\n",
    "- all()\n",
    "- any()\n",
    "- isel()\n",
    "- sel()\n",
    "\n",
    "\n",
    "#### Format and file methods\n",
    "\n",
    "- to_array\n",
    "- to_dask_dataframe\n",
    "- to_dataframe\n",
    "- to_dict\n",
    "- to_netcdf\n",
    "- to_zarr\n",
    "- load\n",
    "\n",
    "#### `dask.array` chunking\n",
    "\n",
    "- chunk\n",
    "- chunks\n",
    "\n",
    "\n",
    "#### four categories of content of a Dataset (objects with their own attributes)\n",
    "\n",
    "- .attrs\n",
    "- .coords\n",
    "- .data_vars\n",
    "- .dims\n",
    "\n",
    "\n",
    "#### assessing content\n",
    "\n",
    "- count\n",
    "\n",
    "\n",
    "#### selecting content\n",
    "\n",
    "\n",
    "\n",
    "#### Sir Not-yet-summarized methods\n",
    "\n",
    "- apply\n",
    "- argmax\n",
    "- argmin\n",
    "- argsort\n",
    "- assign\n",
    "- assign_attrs\n",
    "- assign_coords\n",
    "- astype\n",
    "- bfill\n",
    "- broadcast_equals\n",
    "- clip\n",
    "- close\n",
    "- combine_first\n",
    "- compute\n",
    "- conj\n",
    "- conjugate \n",
    "- copy\n",
    "- cumprod\n",
    "- cumsum\n",
    "- diff\n",
    "- differentiate\n",
    "- drop\n",
    "- dropna\n",
    "\n",
    "- dump_to_store\n",
    "- encoding\n",
    "- equals\n",
    "- expand_dims\n",
    "- ffill\n",
    "- fillna\n",
    "- filter_by_attrs\n",
    "- from_dataframe\n",
    "- from_dict\n",
    "- get\n",
    "- get_index\n",
    "- groupby\n",
    "- groupby_bins\n",
    "- identical\n",
    "- imag\n",
    "- indexes\n",
    "- info\n",
    "- interp\n",
    "- interp_like\n",
    "- interpolate_na\n",
    "- isel_points \n",
    "- isin\n",
    "- isnull\n",
    "- items\n",
    "- keys\n",
    "- load_store\n",
    "- loc\n",
    "- max\n",
    "- mean\n",
    "- median\n",
    "- merge\n",
    "- min\n",
    "- nbytes\n",
    "- notnull\n",
    "- persist\n",
    "- pipe\n",
    "- prod\n",
    "- quantile\n",
    "- rank\n",
    "- real\n",
    "- reduce\n",
    "- reindex\n",
    "- reindex_like\n",
    "- rename() will rename Data variables returning a new Dataset; not 'in place'\n",
    "- reorder_levels\n",
    "- resample\n",
    "- reset_coords\n",
    "- reset_index\n",
    "- roll\n",
    "- rolling\n",
    "- round\n",
    "- sel_points\n",
    "- set_index\n",
    "- shift\n",
    "- sizes\n",
    "- sortby\n",
    "- squeeze\n",
    "- stack\n",
    "- std\n",
    "- sum\n",
    "- swap_dims() swaps a dimensional for a non-dimensional coordinate\n",
    "- transpose\n",
    "- unstack\n",
    "- update\n",
    "- values\n",
    "- var\n",
    "- variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dads` DataArray Dataset\n",
    "\n",
    "* We start with a 3D ndarray `cube`\n",
    "* Cast this as a dask array\n",
    "* Cast this as a DataArray\n",
    "* Cast this as an xr.Dataset `dads`\n",
    "\n",
    "\n",
    "### The Dataset summarized\n",
    "\n",
    "\n",
    "`print(dir(dads))` produces a vast list of state attributes and method attributes (110 of them!)\n",
    "These are sorted out here as an exercise in gaining familiarity with xarray Datasets. At the top level \n",
    "a Dataset is composed of four objects:\n",
    "\n",
    "- An OrderedDict of attributes\n",
    "- Dataset coordinates: Analogous to a key:value Dictionary of DataArrays.\n",
    "- Dataset dimensions (which are 'Frozen')\n",
    "- DataVariables containing data distributed across some of these dimensions, optionally using the coordinates\n",
    "\n",
    "\n",
    "These four objects are instances of four classes; so each has its own attributes; and \n",
    "so on down into various weeds. At the moment we are interested in this high level of the `dads` Dataset: \n",
    "I indicate methods in what follows using `.method(arg[s])` with some examples.  \n",
    "\n",
    "\n",
    "#### Related terminology\n",
    "\n",
    "- Python Mapping is an important construct in the design of this machinery (stub remark).\n",
    "- methods: method functions are declared within a class with an explicit first argument representing that \n",
    "object (the Dataset) which is provided implicitly by the method call; so the method has access to the \n",
    "entirety of the Dataset object, referring to it as `self`.\n",
    "- `xr.DataArray` also has four components: `values`, `dims`, `coords`, and `attrs`. `dims` are analogous to\n",
    "an `axis` in numpy. (A DataArray can also optionally be assigned a `name`: `fu = xr.DataArray(data=3, name='bar')`.\n",
    "- `dask` builds graph representations for dynamic task scheduling needed to perform out-of-core computations. It mimics `Pandas` DataFrames by having its own DataFrames and likewise mimics the `np.ndarray` via `dask.array`; with the \n",
    "user-crucial addition of the concept of the chunk. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<getitem, shape=(), dtype=float64, chunksize=()>\n",
      "dask.array<array, shape=(10, 6, 7), dtype=float64, chunksize=(10, 1, 1)>\n",
      "Describe the DataArray:\n",
      " <xarray.DataArray 'array-1fa3948926acce3f8440e8a243559446' (tt: 10, xx: 6, yy: 7)>\n",
      "dask.array<shape=(10, 6, 7), dtype=float64, chunksize=(10, 1, 1)>\n",
      "Coordinates:\n",
      "  * tt       (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * xx       (xx) float64 0.0 2.0 4.0 6.0 8.0 10.0\n",
      "  * yy       (yy) float64 0.0 3.0 6.0 9.0 12.0 15.0 18.0 \n",
      "\n",
      "Regarde: The data do not print; they just indicate a dask array:\n",
      " dask.array<array, shape=(10, 6, 7), dtype=float64, chunksize=(10, 1, 1)> \n",
      "\n",
      "attributes: OrderedDict() \n",
      "\n",
      "coords: Coordinates:\n",
      "  * tt       (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * xx       (xx) float64 0.0 2.0 4.0 6.0 8.0 10.0\n",
      "  * yy       (yy) float64 0.0 3.0 6.0 9.0 12.0 15.0 18.0 \n",
      "\n",
      "dimensions: Frozen(SortedKeysDict({'tt': 10, 'xx': 6, 'yy': 7})) \n",
      "\n",
      "data_vars: Data variables:\n",
      "    speedfield  (tt, xx, yy) float64 dask.array<shape=(10, 6, 7), chunksize=(10, 1, 1)> \n",
      "\n",
      "No append method in the data_vars:\n",
      " ['get', 'items', 'keys', 'values', 'variables'] \n",
      "\n",
      "speedfield\n",
      "\n",
      "\n",
      "<class 'xarray.core.dataarray.DataArray'>\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell follows Scott Henderson's example to create a bunch of linear trends in time\n",
    "#   across a 2D spatial grid, roughed up with a bit of noise.\n",
    "\n",
    "nt = 10                                # Ten elements in the time dimension\n",
    "nx = 6                                 #     Six in the x\n",
    "ny = 7                                 #     Seven in the y\n",
    "\n",
    "images = np.ones([ny,nx,nt])           # A 3D numpy array of ones: Fast index is time (10), slow is y (7)\n",
    "values = np.arange(nt)                 # A list[] of floats 0., 1., ..., 9.\n",
    "noise = np.random.random([ny,nx,nt])   # A 3D numpy array of uniform random values on [0., 1.]\n",
    "                                       #   which would be indexed via [a, b, c]; not [a][b][c]\n",
    "\n",
    "cubeStart = (images*values)            # A 3D numpy array where the fast index (time) goes 0, 1, ..., 9\n",
    "                                       #   This uses 'broadcast multiplication' element-by-element along\n",
    "                                       #   the fast (right-most) index. What if values[] has length nx or ny? \n",
    "                                       #   Answer: This is no good, won't work. The broadcast list must match \n",
    "                                       #   the fast index in length.\n",
    "cubeNext = cubeStart + noise           # Element-by-element addition of the [0, 1] noise tensor\n",
    "cube = cubeNext.T                      # .T is Transpose: Now the fast index is time, then follows x, then y\n",
    "# print(cubeStart)\n",
    "\n",
    "# hold cube2 in reserve for later: The idea of adding a new DataArray to an existing Dataset\n",
    "cube2 = ((images*values) + noise + noise + noise).T\n",
    "\n",
    "# import dask is necessary to work with dask.array objects \n",
    "tlist = np.arange(nt)\n",
    "xlist = np.arange(0., nx*2., 2.)\n",
    "ylist = np.arange(0., ny*3., 3.)\n",
    "daska = dask.array.from_array(cube, chunks=(nt, 1, 1))\n",
    "print(daska[7,4,2])\n",
    "print(daska)\n",
    "\n",
    "da = xr.DataArray(daska,\n",
    "                  dims=('tt', 'xx', 'yy'),\n",
    "                  coords={'tt': tlist, 'xx': xlist, 'yy': ylist})\n",
    "\n",
    "print('Describe the DataArray:\\n', da, '\\n')\n",
    "print('Regarde: The data do not print; they just indicate a dask array:\\n', da.data, '\\n')\n",
    "\n",
    "dads=da.to_dataset(name='speedfield')\n",
    "\n",
    "# dir(dads)          # this gives a long listing that includes attrs, dims, coords, data_vars as elements of.\n",
    "                     #   We see these listed prominently when we print the Dataset. \n",
    "print('attributes:', dads.attrs, '\\n')\n",
    "print('coords:', dads.coords, '\\n')\n",
    "print('dimensions:', dads.dims, '\\n')\n",
    "print('data_vars:', dads.data_vars, '\\n')\n",
    "print('No append method in the data_vars:\\n', g.dirnou(dads.data_vars), '\\n')\n",
    "\n",
    "for dv in dads.data_vars: print(dv)\n",
    "print('\\n')\n",
    "\n",
    "# print(type(dads.attrs))\n",
    "# print(type(dads.coords))\n",
    "# print(type(dads.dims))\n",
    "# print(type(dads.data_vars))\n",
    "\n",
    "print(type(dads.tt))\n",
    "print(dads.tt.data)\n",
    "print('\\n')\n",
    "\n",
    "# To see the vast composition of a Dataset (state attributes and methods) use 'print(dir(dads))'.\n",
    "# The next cell elaborates all of this content for the dads Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tt coordinate data type is: <class 'numpy.ndarray'>\n",
      "the tt coordinate data describes itself: [0 1 2 3 4 5 6 7 8 9]\n",
      "the tt coordinate self-identifies as: <xarray.DataArray 'tt' (tt: 10)>\n",
      "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Coordinates:\n",
      "  * tt       (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "type of the tt coordinate is: <class 'xarray.core.dataarray.DataArray'>\n",
      "converting the coordinate data to a list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "dads Dataset: <xarray.Dataset>\n",
      "Dimensions:     (tt: 10, xx: 6, yy: 7)\n",
      "Coordinates:\n",
      "  * tt          (tt) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * xx          (xx) float64 0.0 2.0 4.0 6.0 8.0 10.0\n",
      "  * yy          (yy) float64 0.0 3.0 6.0 9.0 12.0 15.0 18.0\n",
      "Data variables:\n",
      "    speedfield  (tt, xx, yy) float64 dask.array<shape=(10, 6, 7), chunksize=(10, 1, 1)> \n",
      "\n",
      "dads.speedfield has type: <class 'xarray.core.dataarray.DataArray'> \n",
      "\n",
      "speedfield with indices 1, 2, 3 (tt, xx, yy) is a DataArray:\n",
      " <xarray.DataArray 'speedfield' ()>\n",
      "dask.array<shape=(), dtype=float64, chunksize=()>\n",
      "Coordinates:\n",
      "    tt       int64 1\n",
      "    xx       float64 4.0\n",
      "    yy       float64 9.0 \n",
      "\n",
      "speedfield data value at same:\n",
      " 1.642824274460157 \n",
      "\n",
      "(speedfield with indices 10, 2, 3 (tt, xx, yy) fails with dimension 0 out of bounds)\n",
      "\n",
      "1.960462029769114\n",
      "1.5607363314531424\n",
      "1.642824274460157\n",
      "1.5159296413307188\n",
      "1.3511651027931313\n",
      "1.9581018960808396\n",
      "[0.1295798143860264, 1.642824274460157, 2.359036613796678, 3.7241057402743842, 4.3972553670051155, 5.434152142885317, 6.901777339469943, 7.9871844917501065, 8.189487203399684, 9.08100305524928]\n",
      "[1.960462029769114, 1.5607363314531424, 1.642824274460157, 1.5159296413307188, 1.3511651027931313, 1.9581018960808396]\n",
      "[1.6442198942444746, 1.6769186051905427, 1.9622083861803237, 1.642824274460157, 1.4048161675076154, 1.1064389712248355, 1.2537921589186067]\n",
      "[ 0.  3.  6.  9. 12. 15. 18. 21. 24. 27.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.00000000e+00, 1.62526165e-15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In top down order: \n",
    "#   We have a 'data array data set' dads: DataSet(One DataArray named 'speedfield')\n",
    "#     This has a 'tt' dimension and an associated 'tt' coordinate. \n",
    "#     The 'tt' coordinate is a DataArray with 10 int64 values\n",
    "#     Using the .data extension to this the coordinate gives an np.ndarray.\n",
    "#     This prints as a space-delimited array (not a comma-delimited list)\n",
    "#     At need it could be converted to a list using .tolist()\n",
    "# \n",
    "print('the tt coordinate data type is:', type(dads.tt.data))\n",
    "print('the tt coordinate data describes itself:', dads.tt.data)\n",
    "print('the tt coordinate self-identifies as:', dads.tt)\n",
    "print('type of the tt coordinate is:', type(dads.tt))\n",
    "print('converting the coordinate data to a list:', dads.tt.data.tolist())\n",
    "\n",
    "# The dads Dataset itself has just the one Data variable 'speedfield'.\n",
    "#   This is also a DataArray; indexed by three dimensional indices\n",
    "#   \n",
    "print('dads Dataset:', dads, '\\n')\n",
    "print('dads.speedfield has type:', type(dads.speedfield), '\\n')\n",
    "print('speedfield with indices 1, 2, 3 (tt, xx, yy) is a DataArray:\\n', dads.speedfield[1,2,3],'\\n')\n",
    "print('speedfield data value at same:\\n', float(dads.speedfield[1,2,3]),'\\n')\n",
    "print('(speedfield with indices 10, 2, 3 (tt, xx, yy) fails with dimension 0 out of bounds)\\n')\n",
    "\n",
    "for a in dads.speedfield[1,:,3]: print(float(a))\n",
    "\n",
    "print([float(a) for a in dads.speedfield[:,2,3]])\n",
    "print([float(a) for a in dads.speedfield[1,:,3]])\n",
    "print([float(a) for a in dads.speedfield[1,2,:]])\n",
    "# print('speedfield along the x axis:\\n', float(dads.speedfield[1,:,3]))\n",
    "\n",
    "y=np.arange(0.,30.,3); print(y)\n",
    "np.polyfit(dads.tt.data, y, 1)\n",
    "\n",
    "# dads1 = xr.Dataset({'tempo': (['x', 'y', 'time'],  temp),\n",
    "#    ....:                  'precipitation': (['x', 'y', 'time'], precip)},\n",
    "#    ....:                 coords={'lon': (['x', 'y'], lon),\n",
    "#    ....:                         'lat': (['x', 'y'], lat),\n",
    "#    ....:                         'time': pd.date_range('2014-09-06', periods=3),\n",
    "#    ....:                         'reference_time': pd.Timestamp('2014-09-05')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'fred' (waviness: 7)>\n",
      "array([ 0. ,  2.1,  3.9,  nan,  nan, 10. , 12.1])\n",
      "Coordinates:\n",
      "  * waviness  (waviness) int64 0 1 2 3 4 5 6\n",
      "<xarray.DataArray 'fred' (waviness: 5)>\n",
      "array([ 0. ,  2.1,  3.9, 10. , 12.1])\n",
      "Coordinates:\n",
      "  * waviness  (waviness) int64 0 1 2 5 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0082089552238807"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relocate\n",
    "# shows a use of .dropna() under simple circumstances\n",
    "\n",
    "x=xr.DataArray([0., 2.1, 3.9, np.nan, np.nan, 10., 12.1], name='fred', coords=[('waviness', range(7))])\n",
    "print(x)\n",
    "\n",
    "y=x.dropna('waviness')\n",
    "print(y)\n",
    "\n",
    "fit = np.polyfit(x.dropna('waviness').waviness, x.dropna('waviness').data, 1); fit[0]  # slope of about 2.0\n",
    "\n",
    "# fit1 = np.polyfit(x.waviness, x.data, 1); fit1[0]        # produces a nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# golive3 LS learning path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b52caeb890d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# determine the lat/lon bounding box of the aggregated region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mxHi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0myHi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mn0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vv' is not defined"
     ]
    }
   ],
   "source": [
    "# relocate this to a coordinate section\n",
    "\n",
    "# Determining how many elements in a 1-D dimension: Dataset uses 'dims' and DataArray uses 'sizes'\n",
    "# vv.to_dataset().dims['x']\n",
    "# vv.sizes['x']\n",
    "\n",
    "# determine the lat/lon bounding box of the aggregated region\n",
    "xHi = vv.sizes['x'] - 1\n",
    "yHi = vv.sizes['y'] - 1\n",
    "n0 = vv.y[0].data\n",
    "n1 = vv.y[yHi].data\n",
    "e0 = vv.x[0].data\n",
    "e1 = vv.x[xHi].data\n",
    "print(e0, e1, n0, n1, '\\n')\n",
    "print('corner geographical coordinates:')\n",
    "print(utm.to_latlon(e0, n0, 7, 'V'))\n",
    "print(utm.to_latlon(e1, n0, 7, 'V'))\n",
    "print(utm.to_latlon(e0, n1, 7, 'V'))\n",
    "print(utm.to_latlon(e1, n1, 7, 'V'))\n",
    "print('\\n')\n",
    "print('latitude band approx', '%.1f' % (2.6*111.), 'km')\n",
    "\n",
    "# moves vv back to Dataset status 'vvds' but renames the Data variable 'vv'\n",
    "# vvds=vv.to_dataset(name='vv')\n",
    "# print(vvds)                        # time, x, y dimensions and the Data variable 'vv'\n",
    "# vvds['vv'].values          # prints a bunch of edge nans; and ellipses... not interesting\n",
    "# print(vvds.vv.sel(y=6710000.,x=500000.,method='nearest').data)    # ...is 75 values, mostly nan\n",
    "\n",
    "# relocate this to a time section\n",
    "# This converts datetime64 to epoch-relative times (floats)\n",
    "# See also Joe's inline conversion example that uses .astype() on Stack Overflow\n",
    "#   This has been commented out in the practice code for solving the LS implementation\n",
    "#   on the 'cube' array\n",
    "if False:\n",
    "    # I would like a time axis that has decimal time in some familiar unit like 1 day. Why? \n",
    "    #   Because when I try to fit a line to the data it complains...\n",
    "    # Since our time range is 2013 to 2018 we will have values of a couple thousand days; \n",
    "    #   but that is pretty reasonable particularly when our data for speed are in meters per day.\n",
    "    # The first step is to choose some epoch; I used January 1 2013 as prior to all the GOLIVE data.\n",
    "    # With this epoch in hand we convert from datetime.datetime to np.datetime64.\n",
    "    # We then reference a datetime in the vvds Dataset, subtract the epoch and convert to (24-hour) units\n",
    "    dtEpoch = datetime(2013,1,1,0,0,0)\n",
    "    dt64Epoch = np.datetime64(datetime(2013,1,1,0,0,0))\n",
    "    ts = (vvds.time[0].data - dt64Epoch) / np.timedelta64(24, 'h')\n",
    "    print(ts, 'days from Jan 1 2013 to the first timestamp of the Dataset:', vvds.time[0].data)\n",
    "\n",
    "    # This next bit converts the vvds datetime64 version of time to epoch time in decimal days\n",
    "    #   ...but since this is done above it will throw an error now\n",
    "    def ETimeDDays(timeX): return (timeX - dt64(datetime(2013,1,1))) / td64(24, 'h')\n",
    "    vvds['time'] = ('time', [ETimeDDays(atime.data) for atime in vvds.time])\n",
    "\n",
    "# vvds.coords          # where time is datetime64; with hours added to avoid collisions\n",
    "# vvds.dims            # 75 source results x (spatial extent)\n",
    "# print(vvds)          # the Dataset overview; but now time will be a float\n",
    "# vvds.count()         # produces like 10,000,000 which is perhaps the non-nan count?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "There are two types of `coordinates` in `xarray`: Dimension coordinates (1D, correspond precisely by name to \n",
    "their `dimension`, marked by an asterisk (\\*) as above; and non-dimension coordinates. These latter contain\n",
    "coordinate data but are not a dimension coordinate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relocate\n",
    "# This cell operated on a Datasetwith the idea of isolating a single location \n",
    "# The learning idea would support 'I have a vast array; what is the time series at some point of interest'\n",
    "# What is needed is 'how to choose that point of interest'\n",
    "\n",
    "# %%time\n",
    "# \n",
    "# vvds.assign_coords(dtime=EpochTimeDecimalDays(vvds.time))\n",
    "# vvds.dtime=vvds.time.\n",
    "# print(dir(vvds.time[0].data))\n",
    "# print(vvds.time[0].data)\n",
    "# print(type(vvds.time[0].data))\n",
    "# dir(vvds.time)\n",
    "# \n",
    "# dsRob = vvds.chunk(chunks={'time':-1, 'y':400, 'x':400})\n",
    "# print(dsRob, '\\n')\n",
    "# timeseries = dsRob.vv\n",
    "# apoint = timeseries.sel(y=6710000.,x=500000.,method='nearest')\n",
    "# print(apoint.data)            \n",
    "# print(vvds.vv.sel(y=6710000.,x=500000.,method='nearest').data)     # prints 75 values, mostly nan\n",
    "# timeseries.plot()\n",
    "# print(dsRob.speedfield.sel(y=6710000.,x=500000.,method='nearest').data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9e77173d664e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This works with a single location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6728488.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m517888.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlsvel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlstime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsvel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vv' is not defined"
     ]
    }
   ],
   "source": [
    "# Relocate\n",
    "# This continues the theme of the prior cell; but starting over\n",
    "# At a single location: \n",
    "#   - selects out a velocity vector with a time axis\n",
    "#   - creates empty lists lsx and lsy, sets up a time coordinate list lstime\n",
    "#   - using a loop populates lsx[] and lsy[] with only non-nan values\n",
    "#   - applies a median filter to the speed data\n",
    "#   - plots four things\n",
    "#     - the unfiltered data\n",
    "#     - the median filter data\n",
    "#     - the fit to unfiltered\n",
    "#     - the fit to filtered\n",
    "# This works with a single location\n",
    "y, x = 6728488.,517888.\n",
    "lsvel = vv.sel(y=y,x=x,method='nearest').data\n",
    "lstime, lsx, lsy = vv['time'], [], []\n",
    "for d in range(len(lsvel)):\n",
    "    if not np.isnan(lsvel[d]): \n",
    "        lsx.append(float(lstime[d].data))\n",
    "        lsy.append(lsvel[d])\n",
    "lsymf = mf(lsy, kernel_size=3); \n",
    "fig,axes = plt.subplots(1); fig.set_size_inches(6,4)\n",
    "axes.set(xlabel='time (days)', ylabel = 'm / d', title='signal (black) and median filter (red)')\n",
    "axes.plot(lsx, lsy, color='black'); axes.plot(lsx, lsymf, color='red')\n",
    "fit = np.polyfit(lsx, lsymf, 1); fitx=[lsx[0],lsx[-1]]; fity=[fit[1] + fit[0]*fitx[0],fit[1] + fit[0]*fitx[1]]\n",
    "axes.plot(fitx, fity, color='blue')\n",
    "fit0 = np.polyfit(lsx, lsy, 1); fitx0=[lsx[0],lsx[-1]]; fity0=[fit0[1] + fit0[0]*fitx0[0],fit0[1] + fit0[0]*fitx0[1]]\n",
    "axes.plot(fitx0, fity0, color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with nan missing values in a LS fit\n",
    "\n",
    "- xarray.DataArray is a labeled, multi-dimensional array\n",
    "  - DataArray contents\n",
    "    - values: a numpy.ndarray holding the array’s values (in an xr.Dataset these are Data variables)\n",
    "    - dims: dimension names for each axis (e.g., ('x', 'y', 'z'))\n",
    "    - coords: a dict-like container of arrays (coordinates) that label each point \n",
    "      - e.g. 1-dimensional arrays of numbers, datetime objects or strings\n",
    "    - attrs: an OrderedDict to hold arbitrary metadata (attributes)\n",
    "    - name: optional string; the name for the data\n",
    "  - Creating a DataArray\n",
    "    - The DataArray constructor takes:\n",
    "      - data: a multi-dimensional array of values (e.g., a numpy ndarray, Series, DataFrame or Panel)\n",
    "      - coords: a list or dictionary of coordinates. \n",
    "        - If a list, it should be a list of tuples where \n",
    "          - the first element is the dimension name and \n",
    "          - the second element is the corresponding coordinate array_like object\n",
    "      - dims: a list of dimension names. If omitted and coords is a list of tuples, dimension names are taken from coords.\n",
    "      - attrs: a dictionary of attributes to add to the instance\n",
    "      - name: a string that names the instance\n",
    "\n",
    "- dropna(dim, how='any', thresh=None)\n",
    "  - Returns a new DataArray with dropped labels for missing values along the provided dimension.\n",
    "  - dim is a string; the name of the dimension along which to drop missing values. \n",
    "    - Dropping along multiple dimensions simultaneously is not yet supported\n",
    "    - how:{‘any’, ‘all’}, optional\n",
    "      - any : if any NA values are present, drop that label\n",
    "      - all : if all values are NA, drop that label\n",
    "     - thresh:int, default None; if supplied, require this many non-NA values\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
